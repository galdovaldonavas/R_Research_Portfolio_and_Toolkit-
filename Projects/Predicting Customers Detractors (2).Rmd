---
title: "Predicting Customer Detractors (Part 2): Assessing Improvement Opportunities via Text Analysis"
output:
  pdf_document: default
  html_document:
    df_print: paged
    self_contained: false
---


# 1. Introduction

This case study explores opportunities to improve customer service, focusing on increasing the likelihood that customers recommend the company.

Specifically, the project presented here is a continuation of a prior exploratory phase: [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090). 

In the present phase, we will focus on **identifying potential improvements and modeling their impact**, using text analysis and modeling how addressing pain points could enhance customer perceptions.

Although based on a real-world project, all data, variables, and insights presented here have been simulated to maintain confidentiality.

The analysis includes:

- Data simulation and cleaning
- Visualization techniques
- Descriptive statistics
- Statistical tests
- Logistic regression modeling
- Simulation-based recommendations
- Creation of reusable functions to automate procedures


# 2. Setup

We start by loading the required packages for data manipulation, visualization, modeling, and exporting results.

```{r}
# Data handling
library(dplyr)       # Data manipulation

# Visualization
library(ggplot2)     # General plotting

# Statistical analysis
library(psych)       # Descriptive statistics
library(car)         # VIF and regression diagnostics
```



# 3. Data Simulation

The data simulation will be similar to [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090), but with a random selection of cases for each of the issues we want to analyze, which was taken in the original project to avoid excessive work coding textual comments.  


## 3.1. Activating the Data from the Prior Section of the Project

We first reproduce the original data from [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090), using the code below. For details, please refer to the data simulation section on that project.  

```{r}

# Set seed for reproducibility
set.seed(1000)

# Define dataset size 
data.n <- 40000  # Large enough to allow subgroup analysis despite unbalanced category probabilities

# Initialize dataframe with IDs
data <- data.frame(id = factor(1:data.n))


# ------ 1. Demographic Information and Contextual Variables

# Simulate age with a log-normal distribution, capped between 15 and 90
data$age <- round(rlnorm(n = data.n, meanlog = log(40), sdlog = log(1.4)))
data$age[data$age > 90] <- 90
data$age[data$age < 15] <- 15

# Simulate gender
data$gender <- factor(sample(c("man", "woman"),
                             prob = c(0.5, 0.5),
                             replace = TRUE, size = data.n))

# Simulate reason for contacting
data$reason <- factor(sample(c("incorrect_item", "delay", "status", "cancellation", "other"),
                             prob = c(0.20, 0.30, 0.20, 0.10, 0.20),
                             replace = TRUE, size = data.n))

# Simulate contact method
data$method <- factor(sample(c("chat", "web_form", "email", "phone"),
                             prob = c(0.40, 0.10, 0.15, 0.35),
                             replace = TRUE, size = data.n))

# Simulate country (two fictional countries for anonymity)
data$country <- factor(sample(c("Drinkland", "Eatland"),
                              prob = c(0.5, 0.5),
                              replace = TRUE, size = data.n))



# ------ 3. Customer Complaints

## Complaints about connection issues
# Base probability of a connection complaint: 10%
prob_connection <- rep(0.10, data.n)
# In Drinkland, probability is doubled
prob_connection[data$country == "Drinkland"] <- prob_connection[data$country == "Drinkland"] * 2
# Ensure probability values remain within [0, 1]
prob_connection [prob_connection > 1] <- 1
prob_connection [prob_connection < 0] <- 0
# Generate binary variable based on probabilities
data$complain.connect <- rbinom(n = data.n, size = 1, prob = prob_connection)
# Check distribution across countries
with(data, prop.table(table(complain.connect, country), margin = 2))


## Complaints about slow response
# Base probability of a slow response complaint: 5%
prob_slow_response <- rep(0.05, data.n)
# Email contacts: 6x higher likelihood
prob_slow_response[data$method == "email"] <- prob_slow_response[data$method == "email"] * 6
# Chat and web_form: 3x higher likelihood
prob_slow_response[data$method %in% c("chat", "web_form")] <- prob_slow_response[data$method %in% c("chat", "web_form")] * 3
# Ensure probability values remain within [0, 1]
prob_slow_response [prob_slow_response > 1] <- 1
prob_slow_response [prob_slow_response < 0] <- 0
# Generate binary variable
data$complain.sp.respond <- rbinom(n = data.n, size = 1, prob = prob_slow_response)
# Check distribution across contact methods
with(data, prop.table(table(complain.sp.respond, method), margin = 2))


## Complaints about slow resolution
# Base probability of a slow resolution complaint: 10%
prob_slow_resolution <- rep(0.10, data.n)
# If contact is via chat and reason is incorrect_item → 5x higher likelihood
is_chat_incorrect <- data$method == "chat" & data$reason == "incorrect_item"
prob_slow_resolution[is_chat_incorrect] <- prob_slow_resolution[is_chat_incorrect] * 5
# Ensure probability values remain within [0, 1]
prob_slow_resolution [prob_slow_resolution > 1] <- 1
prob_slow_resolution [prob_slow_resolution < 0] <- 0
# Generate binary variable
data$complain.sp.solve <- rbinom(n = data.n, size = 1, prob = prob_slow_resolution)
# Check distribution by reason and method
with(data, prop.table(table(complain.sp.solve, reason, method), margin = c(2, 3)))


## Complaints about having to repeat information
# Base probability of a repetition complaint: 2%
prob_repeat_info <- rep(0.02, data.n)
# If contact reason is cancellation → 10x higher likelihood
prob_repeat_info[data$reason == "cancellation"] <- prob_repeat_info[data$reason == "cancellation"] * 10
# Ensure probability values remain within [0, 1]
prob_repeat_info [prob_repeat_info > 1] <- 1
prob_repeat_info [prob_repeat_info < 0] <- 0
# Generate binary variable
data$complain.repeat <- rbinom(n = data.n, size = 1, prob = prob_repeat_info)
# Check distribution across contact reasons
with(data, prop.table(table(complain.repeat, reason), margin = 2))


## Other types of complaints (uniform distribution)
# Constant probability of 20% for other unspecified complaints
data$complain.other <- rbinom(n = data.n, size = 1, prob = 0.20)
# Check distribution
with(data, prop.table(table(complain.other)))


# ------ 3. NPS scores

# Simulate base NPS scores assuming no complaints (mean = 9, sd = 2)
data$nps.score <- rnorm(data.n, mean = 9, sd = 2)

# Apply fixed penalties based on complaints
# -3 for connection issues
# -4 for slow response
# -6 for slow resolution
# -2 for repeated information
# -1 for other complaints
data$nps.score <- data$nps.score -
  3 * data$complain.connect -
  4 * data$complain.sp.respond -
  6 * data$complain.sp.solve -
  2 * data$complain.repeat -
  1 * data$complain.other 

# Ensure scores stay within the 0–10 range
data$nps.score[data$nps.score < 0] <- 0
data$nps.score[data$nps.score > 10] <- 10 

# Convert to integer values (using floor)
data$nps.score <- floor(data$nps.score)

# Add placeholder for open-text comments
data$open.comment <- rep("bla bla", data.n)

# Visualize score distribution
barplot(table(data$nps.score), ylab = "Frequency", xlab = "NPS Scores")
with(data, prop.table(table(data$nps.score)))

## Create NPS segments based on score values

data$nps.segment <- rep(NA_character_, data.n) # Initialize empty character variable

data$nps.segment[data$nps.score <= 6] <- "detractor" 
data$nps.segment[data$nps.score > 6 & data$nps.score < 9] <- "passive"
data$nps.segment[data$nps.score >= 9] <- "promoter" # Assign segment based on score range

data$nps.segment <- factor(data$nps.segment, levels = c("detractor", "passive", "promoter")) # Convert to factor

# Step 4: Check distribution across NPS segments
with(data, prop.table(table(nps.segment)))


#------ Satisfaction scores (1 to 5 scale)

# Generate satisfaction scores based on NPS
# We use a normal distribution centered at 3, with some variability (sd = 0.5)
# and add a scaled component based on NPS to simulate a positive relationship.
data$satisfaction <- floor(
  rnorm(data.n, mean = 3, sd = 0.5) + 
  0.9 * (1 + as.numeric(scale(data$nps.score)))
)

# Ensure scores stay within the 1–5 range
data$satisfaction[data$satisfaction < 1] <- 1
data$satisfaction[data$satisfaction > 5] <- 5

# Visualize the distribution
barplot(table(data$satisfaction), xlab = "Satisfaction Scores", ylab = "Frequency")
with(data, prop.table(table(satisfaction)))

# Check correlation with NPS scores (Spearman method)
with(data, cor(nps.score, satisfaction, method = "spearman"))

# Set satisfaction to missing for Drinkland
data$satisfaction[data$country == "Drinkland"] <- NA_real_

# Set satisfaction to missing for email and web_form contacts
data$satisfaction[data$method %in% c("email", "web_form")] <- NA_real_

# Introduce 10% additional random missingness among remaining valid values
na_randomizer <- sample(
  c(0, 1),
  size = sum(!is.na(data$satisfaction)),
  replace = TRUE,
  prob = c(0.1, 0.9)
) # Create a random vector (0 = missing, 1 = keep) for non-NA entries
data$satisfaction[which(!is.na(data$satisfaction))[na_randomizer == 0]] <- NA_real_ # Apply randomizer
with(data, prop.table(table(is.na(satisfaction), method, country), margin = 2:3)) # Check final distribution

#Check the results for the whole dataset
str(data)
summary(data)

```
We can see that the database is created as expected: 
* A variable "id" to identify each of the 40000 customers of the customer service for which we had data. 
* The variables "age" and "gender" to account for demographics of the customers. 
* Three factor variables that define the context of the customer service attention: 
  * "country" defines which of the country the customer was attende, either Drinkland or Eatland.
  * "reason" defines the contact reason customers contacted for: cancellations of the order, delays on the order delivery, status of the order, incorrect items received by customers,  or other contact reasons. 
  * "method" defines the contact method used by customers: either chat, email, phone or a web_form. 
* Three variables that define outcomes related to the experience of the customers: 
  * "satisfaction" measured the satisfaction ratings in a scale from 1 to 5. 
  * "nps.score" measured the probability to recommend the service with the Net Promoter Score (scale from 0 to 10)
  * "nps.segment" groups customers based on their NPS scores in detractors (scores 0 to 6), passive (scores 7-8), and promoters (scores 9-10).
* A variable, "open.comment", that contained open feedback from customers, which was used to code the presence of complaints (please note that, for simplifying, we have simulated each comment as "blabla")
* Five dichotomous variables that in the original project were derived from coding the open.comments, and specified whether customers complaint about certain aspects: 
  * "complain.connect" for complaints about connection issues.
  * "complain.sp.respond" for complaints about slow speed in responding, once connection was established. 
  * "complain.sp.solve" for complaints about slow speed for solving the issue. 
  * "complain.repeat" for complaints about needing to repeat information. 
  * "complain.other" for other type of complaints. 

Please note that while we have initially simulated the complain variables for all cases, in the real project this data was not available. They were only available for a sample of cases that we selected within each of the factors we wanted to follow up, once we coded their open comments to identify the complaints. In the next section we simulate the NA cases for the cases that were not selected in that random selection. 


# 4. Discussion of Follow Ups Needed Based on Prior Results

In the prior study [Predicting Customer Detractors (Part 1)](https://rpubs.com/galdovaldonavas/1335090), we observed several contextual factors in customer service that are associated with higher levels of detractors, that is, with a lower probability to recommend our service. We summarize these results in the charts below:

```{r}
# Import the image of the mosaic graph about the predicted detractors across contextual factors
knitr::include_graphics("Predicted.Detractors.png")

```

Based on the evidence (and discussions with stakeholders on it), we prioritize a follow up of cases attended by chat for incorrect item issues, since this factor shows the largest increase in detractors, both in relative and absolute terms. For this purpose, we will compare customer complaints in cases involving incorrect items when attended via chat versus when handled through other channels. 

Since incorrect items on their own are not associated with more detractors, we focus exclusively on cases where they occur in combination with chat attendance.


v2
In the previous phase, the model revealed that chat interactions generally increase the likelihood of detractors, and that the effect is even stronger when chat is combined with incorrect item issues. Since incorrect items alone do not raise detractors, this suggests that the negative impact comes from the interaction of these two factors.

For this reason, in this phase we focus on comparing chat + incorrect item cases vs. chat + other issues. This allows us to isolate the complaints that make the combination of chat and incorrect items particularly problematic.

A broader comparison between chat and other contact channels will be explored in a later phase, to assess whether chat underperforms across all types of issues or mainly in specific scenarios.



In the real project, these results were discussed with stakeholders to prioritize the contextual factors that we wanted to explore further and identify opportunities. 

A potential decision could be prioritizing the identification of improvement opportunities in cases attended by chat and that contact for incorrect item issues, the factor that is associated with higher increases in detractors, both in relative terms and in absolute terms. 

For that, we will compare complaints in cases that experience incorrect item when they are attended through chat versus through other means. 

Since the presence of incorrect items appears to have no effect on additional detractors when is not accompanied by chat attendance, we will not include the comparison of cases of incorrect items versus other issues when chat is not present. 




## 3.2. Simulation of the Random Selection of Cases to Analyze Complaints

To code for the presence of complaints in the open comments, we wanted to select a random sample of at least 100 cases for each of the contextual factors we identified as relevant to predict the probability to recommend the service in the prior project [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090). 

### 3.2.1.Recapitulation of Relevant Contextual Factors

To remember the relevant factors to predict the probability to recommend, we extract an image with the results of a logistic model that predicted the detractors: 

```{r}
# Import the image of the mosaic graph about the predicted detractors across contextual factors
knitr::include_graphics("Predicted.Detractors.png")

```

After showing these results with the stakeholders and discussing with them the objectives, we wanted to follow up with the identification of complaints across all factors that showed significant differences in this graph, specifically: 

* All the contact methods: phone, chat, email, and webform
* All the countries: Drinkland and Eatland.
* Three categories of contact reasons: incorrect items, cancellations, and all other contact reasons. 


### 3.2.2.Stratified Random Sample Across Each Factor of Interest

We first create a variable that groups the contact reasons for only differentiating the categories that we are interested in following up: cancellations, incorrect items, and other. 

```{r}
data$reason.grouped <- NA
data$reason.grouped <- as.factor(ifelse(data$reason == "cancellation", "cancellation", ifelse(data$reason == "incorrect_item", "incorrect_item", "other")))
```

For the remaining contextual factors, method and country, we are interested in following ups across all of their categories, so no changes are needed. 

We proceed with selecting a sample of minimun 100 cases for the combination of each category of interest. 

For that, we specify a reusable function to create random samples across cases. 



```{r}
# Optional: Examine the distribution of our current data across the key factors.
with(data, table(method, reason.grouped, country))



#  --- Define a Function to perform stratified sampling ---
# This function takes the desired number of samples per group (my.n),
# the original dataset (my.data), and the names of the three factor columns
# (my.factor1, my.factor2, my.factor3) as character strings.

f.sample.3f <- function(my.n, my.data, my.factor1, my.factor2, my.factor3){
  
  # Input validation: Ensure factor names are passed as character strings.
  if (!is.character(my.factor1) || !is.character(my.factor2) || !is.character(my.factor3)) {
    stop("The factors have to be character chains, with names within quotation marks.")
  }
  
  # Initialize an empty list to store the sampled subsets from each stratum.
  results <- list() 
  
  # Initialize a counter for indexing elements in the 'results' list.
  k <- 1 
  
  # Iterate through each unique level of the first factor.
  for (i in unique(my.data[[my.factor1]])){
    # Within each level of the first factor, iterate through unique levels of the second factor.
    for(j in unique(my.data[[my.factor2]])){
      # Within each combination of the first two factors, iterate through unique levels of the third factor.
      for (q in unique (my.data[[my.factor3]])){
        
        # Filter the original dataframe to get the subset of data
        current.subset <- my.data[my.data[[my.factor1]] == i & 
                                  my.data[[my.factor2]] == j & 
                                  my.data[[my.factor3]] == q, ]
          
        # Get the number of rows (cases) in the current subset.
        current_rows <- nrow(current.subset)
          
        # Sampling logic based on the size of the current group:
        if(current_rows == 0){
          # If the group has no cases, issue an informative warning and go to the next loop
          warning(paste0("The group (", my.factor1, "=", i, ", ", my.factor2, "=", j, ", ", 
                         my.factor3, "=", q, ") has no cases."))
          next 
        } else if (current_rows >= my.n){
          # If the group has  equal to or greater cases than the desired n, we take a random sample:
          current.subset <- current.subset[sample(current_rows, my.n), ]
        } else if (current_rows < my.n) {
          # If the group has fewer cases than desired n, include all available cases, with a warning.
          warning(paste0("The group (", my.factor1, "=", i, ", ", my.factor2, "=", j, ", ", 
                         my.factor3, "=", q, ") has less cases than the expected n. All available cases will be included."))
        }
          
        # Add the processed subset (either sampled or full) to our list of results.
        results[[k]] <- current.subset
        # Increment the counter for the next element in the list.
        k <- k+1
          
      } # End of the third factor (q) loop
    } # End of the second factor (j) loop
  } # End of the first factor (i) loop

  # Final check: If the 'results' list is empty after all loops,
  # it means no groups could be sampled (e.g., all were empty).
  # In this case, return an empty dataframe.
  if (length(results) == 0) {
    message("No groups met the sampling criteria or all groups were empty. Returning an empty data frame.")
    return(data.frame())
  }
  
  # Combine all dataframes from the 'results' list into a single dataframe.
  sample.df <- do.call(rbind, results)
  
  # Return the final sampled dataframe.
  return(sample.df)
}


```
Now we can apply our formula to sample 100 subjects for each level derived from the combination of the three factors of interest: method, reason, and country

```{r}

# --- Execute the Sampling Function ---

data.complaints <- f.sample.3f(
  my.n = 100,             # Desired number of cases per stratum
  my.data = data,         # Your input dataframe
  my.factor1 = "method",  # Column name for the first factor (as a character string)
  my.factor2 = "reason.grouped",  # Column name for the second factor (as a character string)
  my.factor3 = "country"  # Column name for the third factor (as a character string)
)


# Optional: examine the distribution of our sample across the key factors.
with(data.complaints, table(method, reason.grouped, country))
summary(data.complaints)


```

The data selection is as expected. 

Now we can convert the complaint variables as factors: 

```{r}
#Convert the complaint variables to factors
data.complaints$complain.connect <- factor(data.complaints$complain.connect)
data.complaints$complain.sp.respond <- factor(data.complaints$complain.sp.respond)
data.complaints$complain.sp.solve <- factor(data.complaints$complain.sp.solve)
data.complaints$complain.repeat <- factor(data.complaints$complain.repeat)
data.complaints$complain.other <- factor(data.complaints$complain.other)

#Check the conversion: 
summary(data.complaints)

```
We have the data ready for analysis. 





# 4. Explorations with Descriptives and Visualizations

We first calculate the percentages of complaints across methods and reasons


```{r}

f.prop.2f <- function(my.data, my.dv.list, my.factor1, my.factor2){
  
  # Initialize an empty list to store the sampled subsets from each stratum.
  results <- list() 
  
  # Initialize a counter for indexing elements in the 'results' list.
  p <- 1 
  
  # Obtain the levels of the factors
  f1.levels <- unique (my.data[[my.factor1]])
  f2.levels <- unique (my.data[[my.factor2]])
  
  #Create a loop for each dv and for each level of the factors
    for (dv in my.dv.list){
      for (lf1 in f1.levels){
        for(lf2 in f2.levels){
          
          # Extract the vector, successes and number of cases
          current.vector <- my.data[my.data[[my.factor1]]==lf1 & my.data[[my.factor2]]==lf2, dv]
          current.vector.c <- as.numeric(current.vector[!is.na(current.vector)]) #cleaning missing cases
          n <- length(current.vector.c) # number of cases in the vector
          s <- length(current.vector.c[current.vector.c == 1]) # number of cases satisfying the condition
          
          # Calculate proportions and their 95% CI
          if(n > 0){
            proportion <- s / n #calculating proportions
            binomial.test <- binom.test (s, n) # binomial test to calculate 95% CI of the proportions
            ci_lower <- binomial.test$conf.int[1] #extracting the lower limit of the CI
            ci_upper <- binomial.test$conf.int[2] #extracting the upper limit of the CI    
          }else{
            proportion <- NA
            ci_lower <- NA
            ci_upper <- NA
          }

          # Save the results in a named vector
          results [[p]] <- data.frame(dep.variable = dv, factor1 = lf1, factor2 = lf2, percentage = proportion * 100, 
                           ci_lower.perc = ci_lower * 100, ci_upper.perc = ci_upper * 100, stringsAsFactors = FALSE)
          p <- p + 1 
          
        } # close the loop for factor 2
      } # close the loop for factor 1
    } # close the loop for the dv

  #Combine the results in a dataframe and convert outcomes to numeric columns
  results.df <- (do.call(rbind, results))
  rownames(results.df) <- NULL

  #Return the dataframe
  return(results.df)
}

```


Then we can apply the function to our database

```{r}
#Indicate the dependent variables  in a vector
dv.variables <- c("complain.connect", "complain.sp.respond",  "complain.sp.solve", "complain.repeat", "complain.other")

# Apply the function
prop.df <- f.prop.2f (my.data = data.complaints , my.dv.list = dv.variables, my.factor1 = "method", my.factor2 = "reason.grouped")

#Check if the proportions are as expected
table.connect <- with(data.complaints, table(complain.connect, method, reason.grouped))
prop.connect <-  prop.table(table.connect, margin = 2:3)
prop.connect

```
Finally, we represent the results in a graph

```{r}

# Gráfico
ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold")
  )

```


```{r}
library(ggplot2)
library(RColorBrewer)

ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    vjust = -0.5,
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom"
  )


```



```{r}
library(ggplot2)
library(RColorBrewer)

ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    vjust = -0.5,
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


```

Make the graph



```{r, fig.width=8, fig.height=10}


ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    hjust = -0.7,  # en horizontal cambiamos de vjust -> hjust
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom"
  ) +
  coord_flip()


```

# 5. Discovering Opportunities for Incorrect Item Cases Attended Through Chat

For simplification purposes, we will just depict analysis to identify opportunities for this contextual factor in which users who experience incorrect item deliveries are attended through chat, the case that was associated with more detractors in our prior project. Similar analysis would apply to the follow up of other contextual factors. 

```{r}

```

