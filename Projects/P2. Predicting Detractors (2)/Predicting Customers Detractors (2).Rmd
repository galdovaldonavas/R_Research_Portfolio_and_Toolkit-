---
title: "Predicting Customer Detractors (Part 2): Assessing Improvement Opportunities Via Text Analysis"
output:
  pdf_document: default
  html_document:
    df_print: paged
    self_contained: false
---
Title: Predicting Customer Detractors (Part 2): Analyzing Opportunities From Category Codes of Comments

# 1. Introduction

This case study explores opportunities to improve customer service, focusing on increasing the likelihood that customers recommend the company.

Specifically, the project presented here is a continuation of a prior exploratory phase: [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090). 

In the present phase, we will focus on **identifying potential improvements and modeling their impact**, using text analysis and modeling how addressing pain points could enhance customer perceptions.

Although based on a real-world project, all data, variables, and insights presented here have been simulated to maintain confidentiality.

The analysis includes:

- Data simulation and cleaning
- Visualization techniques
- Descriptive statistics
- Statistical tests
- Logistic regression modeling
- Simulation-based recommendations
- Creation of reusable functions to automate procedures


# 2. Setup

We start by loading the required packages for data manipulation, visualization, modeling, and exporting results.

```{r}
# Data handling
library(dplyr)       # Data manipulation

# Visualization
library(ggplot2)     # General plotting

# Statistical analysis
library(psych)       # Descriptive statistics
library(car)         # VIF and regression diagnostics
```



# 3. Data Simulation

The data simulation will be similar to [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090), but with a random selection of cases for each of the issues we want to analyze, which was taken in the original project to avoid excessive work coding textual comments.  


## 3.1. Activating the Data from the Prior Section of the Project

We first reproduce the original data from [Predicting Customer Detractors (Part 1). Analyzing Contextual Factors Via Logistic](https://rpubs.com/galdovaldonavas/1335090), using the code below. For details, please refer to the data simulation section on that project.  

```{r}

# Set seed for reproducibility
set.seed(1000)

# Define dataset size 
data.n <- 40000  # Large enough to allow subgroup analysis despite unbalanced category probabilities

# Initialize dataframe with IDs
data <- data.frame(id = factor(1:data.n))


# ------ 1. Demographic Information and Contextual Variables

# Simulate age with a log-normal distribution, capped between 15 and 90
data$age <- round(rlnorm(n = data.n, meanlog = log(40), sdlog = log(1.4)))
data$age[data$age > 90] <- 90
data$age[data$age < 15] <- 15

# Simulate gender
data$gender <- factor(sample(c("man", "woman"),
                             prob = c(0.5, 0.5),
                             replace = TRUE, size = data.n))

# Simulate reason for contacting
data$reason <- factor(sample(c("incorrect_item", "delay", "status", "cancellation", "other"),
                             prob = c(0.20, 0.30, 0.20, 0.10, 0.20),
                             replace = TRUE, size = data.n))

# Simulate contact method
data$method <- factor(sample(c("chat", "web_form", "email", "phone"),
                             prob = c(0.40, 0.10, 0.15, 0.35),
                             replace = TRUE, size = data.n))

# Simulate country (two fictional countries for anonymity)
data$country <- factor(sample(c("Drinkland", "Eatland"),
                              prob = c(0.5, 0.5),
                              replace = TRUE, size = data.n))



# ------ 3. Customer Complaints

## Complaints about connection issues
# Base probability of a connection complaint: 10%
prob_connection <- rep(0.10, data.n)
# In Drinkland, probability is doubled
prob_connection[data$country == "Drinkland"] <- prob_connection[data$country == "Drinkland"] * 2
# Ensure probability values remain within [0, 1]
prob_connection [prob_connection > 1] <- 1
prob_connection [prob_connection < 0] <- 0
# Generate binary variable based on probabilities
data$complain.connect <- rbinom(n = data.n, size = 1, prob = prob_connection)
# Check distribution across countries
with(data, prop.table(table(complain.connect, country), margin = 2))


## Complaints about slow response
# Base probability of a slow response complaint: 5%
prob_slow_response <- rep(0.05, data.n)
# Email contacts: 6x higher likelihood
prob_slow_response[data$method == "email"] <- prob_slow_response[data$method == "email"] * 6
# Chat and web_form: 3x higher likelihood
prob_slow_response[data$method %in% c("chat", "web_form")] <- prob_slow_response[data$method %in% c("chat", "web_form")] * 3
# Ensure probability values remain within [0, 1]
prob_slow_response [prob_slow_response > 1] <- 1
prob_slow_response [prob_slow_response < 0] <- 0
# Generate binary variable
data$complain.sp.respond <- rbinom(n = data.n, size = 1, prob = prob_slow_response)
# Check distribution across contact methods
with(data, prop.table(table(complain.sp.respond, method), margin = 2))


## Complaints about slow resolution
# Base probability of a slow resolution complaint: 10%
prob_slow_resolution <- rep(0.10, data.n)
# If contact is via chat and reason is incorrect_item → 5x higher likelihood
is_chat_incorrect <- data$method == "chat" & data$reason == "incorrect_item"
prob_slow_resolution[is_chat_incorrect] <- prob_slow_resolution[is_chat_incorrect] * 5
# Ensure probability values remain within [0, 1]
prob_slow_resolution [prob_slow_resolution > 1] <- 1
prob_slow_resolution [prob_slow_resolution < 0] <- 0
# Generate binary variable
data$complain.sp.solve <- rbinom(n = data.n, size = 1, prob = prob_slow_resolution)
# Check distribution by reason and method
with(data, prop.table(table(complain.sp.solve, reason, method), margin = c(2, 3)))


## Complaints about having to repeat information
# Base probability of a repetition complaint: 2%
prob_repeat_info <- rep(0.02, data.n)
# If contact reason is cancellation → 10x higher likelihood
prob_repeat_info[data$reason == "cancellation"] <- prob_repeat_info[data$reason == "cancellation"] * 10
# Ensure probability values remain within [0, 1]
prob_repeat_info [prob_repeat_info > 1] <- 1
prob_repeat_info [prob_repeat_info < 0] <- 0
# Generate binary variable
data$complain.repeat <- rbinom(n = data.n, size = 1, prob = prob_repeat_info)
# Check distribution across contact reasons
with(data, prop.table(table(complain.repeat, reason), margin = 2))


## Other types of complaints (uniform distribution)
# Constant probability of 20% for other unspecified complaints
data$complain.other <- rbinom(n = data.n, size = 1, prob = 0.20)
# Check distribution
with(data, prop.table(table(complain.other)))


# ------ 3. NPS scores

# Simulate base NPS scores assuming no complaints (mean = 9, sd = 2)
data$nps.score <- rnorm(data.n, mean = 9, sd = 2)

# Apply fixed penalties based on complaints
# -3 for connection issues
# -4 for slow response
# -6 for slow resolution
# -2 for repeated information
# -1 for other complaints
data$nps.score <- data$nps.score -
  3 * data$complain.connect -
  4 * data$complain.sp.respond -
  6 * data$complain.sp.solve -
  2 * data$complain.repeat -
  1 * data$complain.other 

# Ensure scores stay within the 0–10 range
data$nps.score[data$nps.score < 0] <- 0
data$nps.score[data$nps.score > 10] <- 10 

# Convert to integer values (using floor)
data$nps.score <- floor(data$nps.score)

# Add placeholder for open-text comments
data$open.comment <- rep("bla bla", data.n)

# Visualize score distribution
barplot(table(data$nps.score), ylab = "Frequency", xlab = "NPS Scores")
with(data, prop.table(table(data$nps.score)))

## Create NPS segments based on score values

data$nps.segment <- rep(NA_character_, data.n) # Initialize empty character variable

data$nps.segment[data$nps.score <= 6] <- "detractor" 
data$nps.segment[data$nps.score > 6 & data$nps.score < 9] <- "passive"
data$nps.segment[data$nps.score >= 9] <- "promoter" # Assign segment based on score range

data$nps.segment <- factor(data$nps.segment, levels = c("detractor", "passive", "promoter")) # Convert to factor

# Step 4: Check distribution across NPS segments
with(data, prop.table(table(nps.segment)))


#------ Satisfaction scores (1 to 5 scale)

# Generate satisfaction scores based on NPS
# We use a normal distribution centered at 3, with some variability (sd = 0.5)
# and add a scaled component based on NPS to simulate a positive relationship.
data$satisfaction <- floor(
  rnorm(data.n, mean = 3, sd = 0.5) + 
  0.9 * (1 + as.numeric(scale(data$nps.score)))
)

# Ensure scores stay within the 1–5 range
data$satisfaction[data$satisfaction < 1] <- 1
data$satisfaction[data$satisfaction > 5] <- 5

# Visualize the distribution
barplot(table(data$satisfaction), xlab = "Satisfaction Scores", ylab = "Frequency")
with(data, prop.table(table(satisfaction)))

# Check correlation with NPS scores (Spearman method)
with(data, cor(nps.score, satisfaction, method = "spearman"))

# Set satisfaction to missing for Drinkland
data$satisfaction[data$country == "Drinkland"] <- NA_real_

# Set satisfaction to missing for email and web_form contacts
data$satisfaction[data$method %in% c("email", "web_form")] <- NA_real_

# Introduce 10% additional random missingness among remaining valid values
na_randomizer <- sample(
  c(0, 1),
  size = sum(!is.na(data$satisfaction)),
  replace = TRUE,
  prob = c(0.1, 0.9)
) # Create a random vector (0 = missing, 1 = keep) for non-NA entries
data$satisfaction[which(!is.na(data$satisfaction))[na_randomizer == 0]] <- NA_real_ # Apply randomizer
with(data, prop.table(table(is.na(satisfaction), method, country), margin = 2:3)) # Check final distribution

#Check the results for the whole dataset
str(data)
summary(data)

```
We can see that the database is created as expected: 
* A variable "id" to identify each of the 40000 customers of the customer service for which we had data. 
* The variables "age" and "gender" to account for demographics of the customers. 
* Three factor variables that define the context of the customer service attention: 
  * "country" defines which of the country the customer was attende, either Drinkland or Eatland.
  * "reason" defines the contact reason customers contacted for: cancellations of the order, delays on the order delivery, status of the order, incorrect items received by customers,  or other contact reasons. 
  * "method" defines the contact method used by customers: either chat, email, phone or a web_form. 
* Three variables that define outcomes related to the experience of the customers: 
  * "satisfaction" measured the satisfaction ratings in a scale from 1 to 5. 
  * "nps.score" measured the probability to recommend the service with the Net Promoter Score (scale from 0 to 10)
  * "nps.segment" groups customers based on their NPS scores in detractors (scores 0 to 6), passive (scores 7-8), and promoters (scores 9-10).
* A variable, "open.comment", that contained open feedback from customers, which was used to code the presence of complaints (please note that, for simplifying, we have simulated each comment as "blabla")
* Five dichotomous variables that in the original project were derived from coding the open.comments, and specified whether customers complaint about certain aspects: 
  * "complain.connect" for complaints about connection issues.
  * "complain.sp.respond" for complaints about slow speed in responding, once connection was established. 
  * "complain.sp.solve" for complaints about slow speed for solving the issue. 
  * "complain.repeat" for complaints about needing to repeat information. 
  * "complain.other" for other type of complaints. 

Please note that while we have initially simulated the complain variables for all cases, in the real project this data was not available. They were only available for a sample of cases that we selected within each of the factors we wanted to follow up, once we coded their open comments to identify the complaints. In the next section we simulate the NA cases for the cases that were not selected in that random selection. 


# 4. Discussion of Follow Ups Needed Based on Prior Results

In the prior study [Predicting Customer Detractors (Part 1)](https://rpubs.com/galdovaldonavas/1335090), we observed several contextual factors in customer service that are associated with higher levels of detractors, that is, with a lower probability to recommend our service. We summarize these results in the charts below:

```{r}
# Import the image of the mosaic graph about the predicted detractors across contextual factors
knitr::include_graphics("Predicted.Detractors.png")

```

Based on the evidence and stakeholder discussions, we prioritize a follow-up on cases handled via chat that involve incorrect item issues, since this factor shows the largest increase in detractors.

To do this, in the next section we will compare complaints in chat cases involving incorrect items versus chat cases involving other issues. This comparison is designed to isolate the negative effects of combining chat with incorrect items, since chat alone is already associated with higher detractors. By keeping the contact channel constant, we avoid confounding the results with chat’s general negative effect.

A broader comparison across all contact channels can be explored in a later phase.


# 5. Discovering Opportunities for Incorrect Item Cases Attended Through Chat

To identify improvement opportunities in this scenario, we will analyze complaints in the open comments of chat cases involving incorrect items versus chat cases involving other issues.


## 5.1. Random Selection of Cases to Analyze Complaints

Reviewing all comments in the dataset would be an unrealistic workload. Therefore, we will perform this coding and analysis on a sample, as specified in the next section. Please note that although we are working with simulated complaint data, in reality such data was only available for the sampled cases. 

Using the code below, we take a random sample for each of the comparison conditions: chat cases involving incorrect items versus chat cases involving other issues. We set the size of these samples to 200 cases each, which can provide sufficient statistical power and represents an affordable coding workload coding the comments. 

```{r}

# Specify the sample sizes for both samples
sample.n <- 200

# Sample 1: Cases of chat attending incorrect items
subset_chat_incorrect<- data[data$reason == "incorrect_item" & data$method == "chat", ]
subset1.rows <- nrow(subset_chat_incorrect)
sample_chat_incorrect <- subset_chat_incorrect[sample(1:subset1.rows, sample.n), ]
sample_chat_incorrect$condition <- "chat_incorrect_item"

#Sample 2: Cases of chat attending other issues
subset_chat_other <- data[!(data$reason == "incorrect_item") & data$method == "chat", ]
subset2.rows <- nrow(subset_chat_other)
sample_chat_other <- subset_chat_other[sample(1:subset2.rows, sample.n), ]
sample_chat_other$condition <- "chat_other_issues"

#Bind together the two samples in a dataset
data.ch.i <- bind_rows(sample_chat_incorrect, sample_chat_other)
data.ch.i$condition <- factor(data.ch.i$condition)
#Check the final sample
summary(data.ch.i)

```


# 5.2. Evaluating the Presence of Complaints

# 5.2.1. Exploration with Descriptives and Visualizations

We define a function to explore the percentages of complaints across our conditions to compare. We will prepare the desagregation for two factors, one for our condition variable, and another for the factor country, so that we can check if the pattern of results is similar across different countries. 


```{r}

f.prop.2f <- function(my.data, my.dv.list, my.factor1, my.factor2){
  
  # Initialize an empty list to store the sampled subsets from each stratum.
  results <- list() 
  
  # Initialize a counter for indexing elements in the 'results' list.
  p <- 1 
  
  # Obtain the levels of the factors
  f1.levels <- unique (my.data[[my.factor1]])
  f2.levels <- unique (my.data[[my.factor2]])
  
  #Create a loop for each dv and for each level of the factors
    for (dv in my.dv.list){
      for (lf1 in f1.levels){
        for(lf2 in f2.levels){
          
          # Extract the vector, successes and number of cases
          current.vector <- my.data[my.data[[my.factor1]]==lf1 & my.data[[my.factor2]]==lf2, dv]
          current.vector.c <- as.numeric(current.vector[!is.na(current.vector)]) #cleaning missing cases
          n <- length(current.vector.c) # number of cases in the vector
          s <- length(current.vector.c[current.vector.c == 1]) # number of cases satisfying the condition
          
          # Calculate proportions and their 95% CI
          if(n > 0){
            proportion <- s / n #calculating proportions
            binomial.test <- binom.test (s, n) # binomial test to calculate 95% CI of the proportions
            ci_lower <- binomial.test$conf.int[1] #extracting the lower limit of the CI
            ci_upper <- binomial.test$conf.int[2] #extracting the upper limit of the CI    
          }else{
            proportion <- NA
            ci_lower <- NA
            ci_upper <- NA
          }

          # Save the results in a named vector
          results [[p]] <- data.frame(dep.variable = dv, factor1 = lf1, factor2 = lf2, percentage = proportion * 100, 
                           ci_lower.perc = ci_lower * 100, ci_upper.perc = ci_upper * 100, stringsAsFactors = FALSE)
          p <- p + 1 
          
        } # close the loop for factor 2
      } # close the loop for factor 1
    } # close the loop for the dv

  #Combine the results in a dataframe and convert outcomes to numeric columns
  results.df <- (do.call(rbind, results))
  rownames(results.df) <- NULL

  #Return the dataframe
  return(results.df)
}

```


Then we can apply the function to evaluate the presencee of different complaints across our conditions of chat cases attending and not attending incorrect item issues

```{r}
#Indicate the dependent variables  in a vector
dv.variables <- c("complain.connect", "complain.sp.respond",  "complain.sp.solve", "complain.repeat", "complain.other")

# Apply the function
prop.df <- f.prop.2f (my.data = data.ch.i , my.dv.list = dv.variables, my.factor1 = "condition", my.factor2 = "country")

#Check if the proportions are as expected
table.connect <- with(data.ch.i, table(complain.connect, condition, country))
prop.connect <-  prop.table(table.connect, margin = 2:3)
prop.connect # to check the results with prop.table results
prop.df # to see the results
```

We can represent the results in a graph:

```{r}

# Setting the order of the complaints variables
prop.df$dep.variable <- factor(prop.df$dep.variable, levels = c("complain.connect", "complain.repeat", "complain.sp.respond", "complain.sp.solve", "complain.other"))

# Titles for each faceted graph representing a type of complaint
custom_titles <- c(
  complain.connect   = "Connection Problems",
  complain.repeat     = "Need to Repeat Information",
  complain.sp.respond = "Slow Responses",
  complain.sp.solve   = "Slow Resolution",
  complain.other      = "Other Complaints"
)

# Plotting the bar graph
ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  facet_wrap(~ dep.variable, 
             scales = "fixed", 
             axes = "all", 
             labeller = labeller(dep.variable = custom_titles)) +
  labs(
    y = "% of Complaints",
    fill = "Country",
    title = "% of Chat Complaints by Issue Type"
  ) +
  scale_x_discrete(labels = c ("incorrect item", "other issue")) +
  ylim(0, 100) +  
  geom_text(
    aes(label = paste0(round(percentage, 0), "%")),         # label with percentage rounded
    position = position_dodge(width = 0.8),   # match the dodge of bars
    vjust = -3,                             # slightly above the bar
    size = 2.5                                # text size
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.title.x = element_blank(),
    legend.position = c(1, 0),
    legend.justification = c("right", "bottom"),
    legend.title = element_text(size = 10, face = "bold"),
    legend.text  = element_text(size = 10),
    panel.spacing = unit(1, "lines"),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0.5),  
    plot.margin = margin(10, 5, 10, 5)
  )

```

The graphs suggest that chat attention to incorrect item issues and chat attention to other issues differ mainly in the presence of slow resolution complaints. These are substantially more common for incorrect item issues (46%–49% depending on the country) compared to other issues (7%–15%).

The graphs also suggest that this pattern of results is consistent across countries. 


### 5.2.2. Modeling the Presence of Complaints

To formally test the above observations, we estimate binomial logistic regression models for each type of complaint. In these models, country is included as a covariate to account for cultural differences in complaint tendencies. Since our sample have similar proportion of cases for each condition across both countries, multicollinearity is not expected to be an issue.

```{r}
# Specify other issues as the reference level for the condition variable
data.ch.i$condition <- factor(data.ch.i$condition, levels = c("chat_other_issues", "chat_incorrect_item"))

##-- Models for different type of complaints

# Logistic model to predict connection complaints
m.connect <- glm(complain.connect ~ condition + country, data = data.ch.i, family = binomial)
summary(m.connect)

# Logistic model to predict complaints about the need to repeat information
m.repeat <- glm(complain.repeat ~ condition + country, data = data.ch.i, family = binomial)
summary(m.repeat)

# Logistic model to predict slow response complaints
m.respond <- glm(complain.sp.respond ~ condition + country, data = data.ch.i, family = binomial)
summary(m.respond)

# Logistic model to predict slow resolution complaints
m.solve <- glm(complain.sp.solve ~ condition + country, data = data.ch.i, family = binomial)
summary(m.solve)

# Logistic model to predict other complaints
m.other <- glm(complain.other ~ condition + country, data = data.ch.i, family = binomial)
summary(m.other)

```

Similarly to our descriptive exploration, the binomial models indicate that chat attention to incorrect item issues and chat attention to other issues only differ in the presence of slow resolution complaints.

To rule out the possibility that the effect of issue type depended on the country, we also tested interaction models.

```{r}
##-- Models for different type of complaints, including interaction tests

# Logistic model to predict connection complaints
m.connect.i <- glm(complain.connect ~ condition * country, data = data.ch.i, family = binomial)
summary(m.connect.i)

# Logistic model to predict complaints about the need to repeat information
m.repeat.i <- glm(complain.repeat ~ condition * country, data = data.ch.i, family = binomial)
summary(m.repeat.i)

# Logistic model to predict slow response complaints
m.respond.i <- glm(complain.sp.respond ~ condition * country, data = data.ch.i, family = binomial)
summary(m.respond.i)

# Logistic model to predict slow resolution complaints
m.solve.i <- glm(complain.sp.solve ~ condition * country, data = data.ch.i, family = binomial)
summary(m.solve.i)

# Logistic model to predict other complaints
m.other.i <- glm(complain.other ~ condition * country, data = data.ch.i, family = binomial)
summary(m.other.i)

```

Out of the five interaction tests, only one (for complain.repeat) reached nominal significance (p = .033). However, this effect did not survive correction for multiple testing (Bonferroni-adjusted threshold = .01), and it also lacked theoretical or practical relevance. We therefore conclude that complaint patterns are largely consistent across countries. The only robust and substantively meaningful difference is the higher prevalence of slow resolution complaints for incorrect item issues.

For reasons of parsimony and interpretability, we simplify our modeling strategy and focus on predicting slow resolution complaints without including country as a factor:

```{r}

# Binomial model to predict slow resolution complaints excluding the non-significant factors 
m.solve2 <- glm(complain.sp.solve ~ condition, data = data.ch.i, family = binomial)
summary(m.solve2)

# Compare the models with and without the country factor
anova(m.solve2, m.solve, test = "Chisq")

```

The likelihood ratio test confirms that removing the country variable does not significantly reduce model fit. Therefore, we keep as our final model the simplified model that excludes it.

We are now ready to derive meaningful metrics from the model to understand the extent to which the presence of resolution complaints is associated with incorrect item issues.


### 5.2.3. Creating Metrics to Interpret the Model

To interpret the results of our binomial logistic regression, we will compute several complementary metrics for each of the factors:
  * Predicted percentage of successes for the presence of each factor (while holding others constant).
  * Differences in predicted percentages of successes compared to the baseline.
  * Relative probabilities (risk ratios).
  * Odds ratios.

To calculate the predicted proportions, we first need to build a design matrix that represents the presence of each factor, so that we can generate predictions for each scenario separately.

We build the matrix by editing reusable code we have published in my [toolkit for binomial models] (https://github.com/galdovaldonavas/R_Research_Portfolio_and_Toolkit-/blob/main/Toolkit/Regression%20Modeling.%20Logistic%20Binomial.Rmd)


```{r}

#####
# Design Matrix for Predictions
#####

# Extract the factor names from the model, with and without the intercept--- no editions needed
f.names.interc <- names(coef(m.solve2))
f.names <- f.names.interc[-1]

# Create a matrix with 1s on the diagonal (each case represents one factor set to 1) --- no editions needed
my.matrix.df <- as.data.frame(diag(length(f.names.interc)))
my.matrix.df[, 1] <- f.names.interc
names(my.matrix.df) <- c("case", f.names)


# Ensure factor variables match the dataset format. ---editions needed for our factor condition
names(my.matrix.df)[names(my.matrix.df) == "conditionchat_incorrect_item"] <- "condition"
my.matrix.df$condition[my.matrix.df$condition == 1] <- "chat_incorrect_item"
my.matrix.df$condition[my.matrix.df$condition == 0] <- "chat_other_issues"
my.matrix.df$condition <- as.factor(my.matrix.df$condition)

# Quick check of the structure --- no editions needed
str(my.matrix.df)
my.matrix.df



```


We also specify a [function to calculate the metrics from my toolkit for binomial models] (https://github.com/galdovaldonavas/R_Research_Portfolio_and_Toolkit-/blob/main/Toolkit/Regression%20Modeling.%20Logistic%20Binomial.Rmd)

```{r}
#####
#Function to obtain key interpretation metrics for a binomial logistic model
#####


f.metrics.binomial <- function(my.model, my.matrix){
  
  #--------1. Preliminary Checks: 
  
  # Making sure the model is glm binomial
  if (!inherits(my.model, "glm") || my.model$family$family != "binomial") {
    stop("The function requires a binomial model.")
  }
  
  
  #--------2. Odds Ratios
  
  # Obtaining the coefficients and confidence intervals
  coefs <- coef(my.model)
  ci <- confint(my.model)
  intercept <- coefs[1]
  
  # Exponentiation of the coefficients and their CIs to obtain odds ratios
  or <- exp(coefs)
  or_ci <- exp(ci)
  
  
  #--------3. Relative Probabilities (Risk Ratios)
  
  # Calculating the base probability from the intercept
  p0 <- or[1] / (1 + or[1])
  
  # Obtaining relative probabilities from risk ratios and base probability
  rp <- or / ((1 - p0) + (p0 * or))
  rp_ci_low <- or_ci[, 1] / ((1 - p0) + (p0 * or_ci[, 1]))
  rp_ci_high <- or_ci[, 2] / ((1 - p0) + (p0 * or_ci[, 2]))
  
  
  #--------4. Predicted Proportions
  
  # Extract log-odds and their sd for the individual presence of the factors (using the specified matrix)
  pred <- predict(my.model, newdata = my.matrix, type = "link", se.fit = TRUE)

  #Calculate confidence intervals in log-odds
  lower_logit <- pred$fit - 1.96 * pred$se.fit
  upper_logit <- pred$fit + 1.96 * pred$se.fit

  #Specify a function to transform log-odds to probabilities
  f.inv_logit <- function(x) {1 / (1 + exp(-x))}
  
  #Apply the function to the log-odds and the limits of their ci
  predicted_prob <- f.inv_logit(pred$fit) # Predicted probabilities
  lower_predicted_prob <- f.inv_logit(lower_logit) # Lower limit of CI for predicted probabilities
  upper_predicted_prob <- f.inv_logit(upper_logit) # Upper limit of CI for predicted probabilities

  
  #--------5. Differences in Predicted Probabilities via Bootstrap

  # Simulate a distribution of log-odds, for example with 10000 cases
  set.seed(123)
  simulated_log_odds <- as.data.frame(matrix(
  rnorm(10000 * length(pred$fit), mean = pred$fit, sd = pred$se.fit),
  ncol = length(pred$fit), byrow = TRUE
  ))

  # Transform logg-odds to expected probabilities (using the formula specified above)
  simulated_probs <- f.inv_logit(simulated_log_odds)

  # Calculate differences from the first column, which correspond to the intercept probabilities
  diffs <- apply(simulated_probs, 2, function(col){
  col - simulated_probs[[1]]
  })

  # Calculate the means of the differences and 95% CI with percentiles
  prob_diff <- colMeans(diffs)
  lower_prob_diff  <- apply(diffs, 2, quantile, probs = 0.025)
  upper_prob_diff <- apply(diffs, 2, quantile, probs = 0.975)
  
  
  #-------- 6. Combine Results
  
  results <- data.frame(
    Term = names(rp),
    Prediction = as.numeric(predicted_prob)*100,
    Lower_Prediction = as.numeric(lower_predicted_prob)*100,
    Upper_Prediction = as.numeric(upper_predicted_prob)*100,
    Predicted_Change = as.numeric(prob_diff)*100,
    Lower_Predicted_Change = as.numeric(lower_prob_diff)*100,
    Upper_Predicted_Change = as.numeric(upper_prob_diff)*100,
    Relative_Probability = as.numeric(rp),
    Lower_Relative_Probability = as.numeric(rp_ci_low),
    Upper_Relative_Probability = as.numeric(rp_ci_high),
    Odds_Ratio = as.numeric(or),
    Lower_Odds_Ratio = as.numeric(or_ci[,1]),
    Upper_Odds_Ratio = as.numeric(or_ci[,2])
)
  
  # Remove meaningless metrics for intercept
  results[1, c("Predicted_Change",
             "Lower_Predicted_Change",
             "Upper_Predicted_Change",
             "Relative_Probability",
             "Lower_Relative_Probability",
             "Upper_Relative_Probability",
             "Odds_Ratio",
             "Lower_Odds_Ratio",
             "Upper_Odds_Ratio")] <- NA_real_

  
  # Return the results
  return(results)
}


```


We apply the function to our model and the specified matrix: 

```{r}
# Apply the function to the final binomial model
m.solve2.metrics.df <- f.metrics.binomial(m.solve2, my.matrix.df)

# Display the resulting metrics
m.solve2.metrics.df

```

These metrics allow us to translate the coefficients of the logistic model into more intuitive quantities:
* Predicted complaint probabilities: The probability of a slow resolution complaint is 47.5% for incorrect item issues, compared to 11.5% for other cases.
* Relative probability (risk ratio): The probability of complaints is 4.13 times higher for incorrect item issues than for other cases.
* Odds ratio: The odds of complaints are 6.96 times higher for incorrect item issues. Unlike the predicted probabilities, the odds ratio provides an effect size that is independent of the model intercept. 


We can further enhance interpretability with a dot-and-whisker plot for the predicted percentages of complaints across factors:


```{r}

# Add descriptive labels for each factor
m.solve2.metrics.df$Label <- NA_character_
m.solve2.metrics.df$Label[m.solve2.metrics.df$Term == "(Intercept)"] <- 
  "Baseline: Other Issues"
m.solve2.metrics.df$Label[m.solve2.metrics.df$Term == "conditionchat_incorrect_item"] <- 
  "Incorrect Item Issues"


# Create the dot-and-whisker plot for the predictions
ggplot(m.solve2.metrics.df, aes(x = Prediction, 
                    y = reorder(Label, Prediction))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "darkgrey") +
  geom_errorbarh(aes(xmin = Lower_Prediction, xmax = Upper_Prediction), height = 0.2) +
  geom_point(size = 3) +
    geom_text(aes(label = paste(round(Prediction,1), "%")), 
            vjust = -1, size = 3.5) + 
  labs(
    title = "Expected Chat Complaints By Issue Attended",
    x = "% of Complaints",
    y = "Issue Type"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```
The graph clearly illustrates the substantial difference in predicted complaint rates between chats addressing incorrect item issues and those handling other issues. The 95% confidence intervals for the two groups are separated by more than 20 percentage points, highlighting a robust difference.


## 5.3. Further Text Coding & Analyses of Specific Problems

Once we identified that complaints about slow resolution speed were driving the difference between incorrect item issues and other issues within chat cases, it became important to further identify and code for the specific problems users were raising. 

In the original project, this type of qualitative coding is sometimes carried out during the first coding phase whenever such issues could be identified. Otherwise, it was conducted later for categories that showed meaningful differences, as we are doing here.


### 5.3.1. Data Simulation for Specific Problems in Slow Resolution Complaints

To illustrate this coding step, we simulate a distribution of specific problems present in slow resolution complaints, whose distribution varied across cases with incorrect items and other cases: 

* Within the 47.5% of cases of *incorrect items* who complained about slow resolution: 
  * 72% probability of just mentioning difficulties loading photos in the chat
  * 12% probability of just mentioning slow procedures checking information 
  * 4% of probability mentioning both problems 
  * 12% of unespecified problems 
  
* Within the 11.5% of cases of *other issues* who complained about slow resolution: 
  * 5% probability of just mentioning difficulties loading photos in the chat 
  * 47.4% probability of just mentioning slow procedures checking information 
  * 0.2% probability of mentioning both problems 
  * 47.4% probability of unespecified problems
 
 
 
```{r}

# 1) Limpia/crea columnas de problemas (multi-etiqueta)
vars <- c("problem.photo","problem.info","problem.deadline","problem.unspecified")
for(v in vars) data.ch.i[[v]] <- NA_real_

# 2) Parámetros: número de problemas por queja (puedes ajustar por condición si quieres)
#    K = 0 => unspecified; K >= 1 => se asignan K problemas distintos sin reemplazo
pk_other    <- c(`0` = 0.10, `1` = 0.70, `2` = 0.18, `3` = 0.02)   # other issues
pk_incorrect<- c(`0` = 0.05, `1` = 0.70, `2` = 0.22, `3` = 0.03)   # incorrect item

# 3) Pesos por condición para elegir problemas (sin reemplazo)
probs <- c("photo","info","deadline")
w_other     <- c(photo = 0.05, info = 0.60, deadline = 0.35)       # otras incidencias
w_incorrect <- c(photo = 0.70, info = 0.20, deadline = 0.10)       # incorrect item

# 4) Función auxiliar: muestreo sin reemplazo ponderado
sample_weighted_no_replace <- function(items, weights, k){
  if(k <= 0) return(character(0))
  picked <- character(0)
  w <- weights
  for(i in seq_len(k)){
    p <- w / sum(w)
    choice <- sample(items, size = 1, prob = p)
    picked <- c(picked, choice)
    w[choice] <- 0  # quita el elegido (sin reemplazo)
  }
  picked
}

# 5) Asignación fila a fila, SOLO en quienes tienen queja de slow resolution
idx <- which(data.ch.i$complain.sp.solve == 1)

for(i in idx){
  cond <- data.ch.i$condition[i]
  
  # elige distribución de K según condición
  pk <- if(cond == "chat_incorrect_item") pk_incorrect else pk_other
  K  <- as.integer(sample(as.integer(names(pk)), size = 1, prob = pk))
  
  # elige pesos según condición
  w  <- if(cond == "chat_incorrect_item") w_incorrect else w_other
  
  # inicializa a 0 (para quienes tienen queja)
  data.ch.i$problem.photo[i]       <- 0
  data.ch.i$problem.info[i]        <- 0
  data.ch.i$problem.deadline[i]    <- 0
  data.ch.i$problem.unspecified[i] <- 0
  
  if(K == 0){
    # unspecified
    data.ch.i$problem.unspecified[i] <- 1
  } else {
    chosen <- sample_weighted_no_replace(probs, w, K)
    if("photo"    %in% chosen) data.ch.i$problem.photo[i]    <- 1
    if("info"     %in% chosen) data.ch.i$problem.info[i]     <- 1
    if("deadline" %in% chosen) data.ch.i$problem.deadline[i] <- 1
  }
}

# 6) Para quienes NO tienen queja, deja NA (o pon 0 si prefieres)
no_idx <- which(data.ch.i$complain.sp.solve == 0)
data.ch.i[no_idx, c("problem.photo","problem.info","problem.deadline","problem.unspecified")] <- NA_real_


# Check the 

```
 
 
 
```{r}


# Save the levels for the specific problems in slow resolution complaints
levels.sp.solve <- c("Difficulties loading photos", "Slow information check", "Both problems", "Unespecified problem")

# Create an empty variable to code the specific problems in slow resolution complaints
data.ch.i$sp.solve.problem <- NA_character_

# -- Data simulation for slow resolution complaints within *incorrect item cases*
# Create the subset
subset.ii <- data.ch.i[data.ch.i$condition == "chat_incorrect_item" & data.ch.i$complain.sp.solve == 1, ]
# Save the n of the subset
n.subset.ii <- nrow(subset.ii)
# Introduce values for the specific problems in slow resolution complaints
subset.ii$sp.solve.problem <- sample(x = levels.sp.solve, size = n.subset.ii, replace = TRUE, prob = c(.65, .15, .05, .15))

# -- Data simulation for cases experiencing other issues and complaining about slow resolution
# Create the subset
subset.oi <- data.ch.i[data.ch.i$condition == "chat_other_issues" & data.ch.i$complain.sp.solve == 1, ]
# Save the n of the subset
n.subset.oi <- nrow(subset.oi)
# Introduce values for the specific problems in slow resolution complaints
subset.oi$sp.solve.problem <- sample(x = levels.sp.solve, size = n.subset.oi, replace = TRUE, prob = c(0.05, .474, 0.002, .474))

# -- Data simulation for cases not complaining about slow resolution
# Create the subset and keep the NA values
subset.no.c <- data.ch.i[data.ch.i$complain.sp.solve == 0, ]


# -- Integrate the procedures in the dataset
# Regroup the subsets
data.ch.i <- bind_rows(subset.ii, subset.oi, subset.no.c)

# Express the variable as a factor
data.ch.i$sp.solve.problem <- factor(data.ch.i$sp.solve.problem)

# Check the simulation by displaying distribution of coded problems by condition
with(data.ch.i, table(sp.solve.problem, complain.sp.solve, condition))

```
 
 
 
  
```{r}

# Save the number of cases in the dataset
n.data.ch.i <- nrow (data.ch.i)

# ---- Code Simulation for Problems Present in the Slow Resolution Complaints

## - Problems attaching the photo in the chat
# Base probability in other issues: 5%
prob_photo <- rep(0.05, n.data.ch.i)
# For incorrect item issues, this probability is multiplied by 14
prob_photo[data.ch.i$condition == "chat_incorrect_item"] <- prob_photo[data.ch.i$condition == "chat_incorrect_item"] * 15
# Generate binary variable based on probabilities
data.ch.i$problem.photo <- rbinom(n = n.data.ch.i, size = 1, prob = prob_photo)
# Code for the absence of scores in cases with no slow resolution complaints
data.ch.i$problem.photo [data.ch.i$complain.sp.solve == 0] <- NA_real_
# Check distribution across conditions
with(data.ch.i, prop.table(table(problem.photo, condition), margin = 2))


## - Problems of slow process checking the information
# Generate binary variable based on 60% probability for remaining cases
data.ch.i$problem.info <- rbinom(n = n.data.ch.i, size = 1, prob = .60)
# Code for the absence of scores in cases with no slow resolution complaints
data.ch.i$problem.info [data.ch.i$complain.sp.solve == 0] <- NA_real_
# Check distribution across conditions
with(data.ch.i, prop.table(table(problem.info, condition), margin = 2))


## - Problems of failing promised deadlines
# Generate binary variable based on 30% probability
data.ch.i$problem.deadline <- rbinom(n = n.data.ch.i, size = 1, prob = .30)
# Code for the absence of scores in cases with no slow resolution complaints
data.ch.i$problem.deadline [data.ch.i$complain.sp.solve == 0] <- NA_real_
# Check distribution across conditions
with(data.ch.i, prop.table(table(problem.deadline, condition), margin = 2))


## - Unespecified problems in slow resolution complaints
# Create a variable with NAs
data.ch.i$problem.unspecified <- NA_real_
# Input 0 if other problems have specified in slow resolution complaints, 1 otherwise
data.ch.i$problem.unspecified [data.ch.i$problem.photo == 1 | data.ch.i$problem.info == 1 | data.ch.i$problem.deadline == 1 ] <- 0
data.ch.i$problem.unspecified [!(data.ch.i$problem.photo == 1 | data.ch.i$problem.info == 1 | data.ch.i$problem.deadline == 1) & data.ch.i$complain.sp.solve == 1] <- 1
# Check distribution across conditions
with(data.ch.i, prop.table(table(problem.unspecified, condition), margin = 2))

#General check of the distributions
with(data.ch.i, table(problem.photo, problem.info, problem.deadline, problem.unspecified, useNA="ifany"))


```

SEGUIR AQUÍ LA SIMULACIÓN Y EL RESTO DE ANÁLISIS

```
  

  
```{r}

# Save the levels for the specific problems in slow resolution complaints
levels.sp.solve <- c("Difficulties loading photos", "Slow information check", "Unespecific")

# Create an empty variable to code the specific problems in slow resolution complaints
data.ch.i$sp.solve.problem <- NA_character_

# -- Data simulation for cases experiencing incorrect item issues and complaining about slow resolution
# Create the subset
subset.ii <- data.ch.i[data.ch.i$condition == "chat_incorrect_item" & data.ch.i$complain.sp.solve == 1, ]
# Save the n of the subset
n.subset.ii <- nrow(subset.ii)
# Introduce values for the specific problems in slow resolution complaints
subset.ii$sp.solve.problem <- sample(x = levels.sp.solve, size = n.subset.ii, replace = TRUE, prob = c(.70, .20, .10))

# -- Data simulation for cases experiencing other issues and complaining about slow resolution
# Create the subset
subset.oi <- data.ch.i[data.ch.i$condition == "chat_other_issues" & data.ch.i$complain.sp.solve == 1, ]
# Save the n of the subset
n.subset.oi <- nrow(subset.oi)
# Introduce values for the specific problems in slow resolution complaints
subset.oi$sp.solve.problem <- sample(x = levels.sp.solve, size = n.subset.oi, replace = TRUE, prob = c(0.06, .64, .30))

# -- Data simulation for cases not complaining about slow resolution
# Create the subset and keep the NA values
subset.no.c <- data.ch.i[data.ch.i$complain.sp.solve == 0, ]


# -- Integrate the procedures in the dataset
# Regroup the subsets
data.ch.i <- bind_rows(subset.ii, subset.oi, subset.no.c)

# Express the variable as a factor
data.ch.i$sp.solve.problem <- factor(data.ch.i$sp.solve.problem)

# Check the simulation by displaying distribution of coded problems by condition
with(data.ch.i, table(sp.solve.problem, complain.sp.solve, condition))

```

The data has been simulated as expected. We proceed with the analyses. 



### 5.3.2. Exploratory Analyses of Specific Problems

To explore whether the higher complains about slow resolution for incorrect item issues is also associated with a different nature of problems, we can conduct a table of proportions for incorrect items versus other issues

```{r}
#Calculate a frequency table and save it
table.problems <- with(data.ch.i, table(sp.solve.problem, condition))
table.problems
# Calculate the table of proportions from the frequency table
prop.table(table.problems, margin =2)
#Visualize the proportions with a mosaic plot
plot (table.problems)

```
The plot and the table of proportions show that the cases of incorrect items differ not only in having more complaints about slow resolution, but also on the nature of these complaints: most of them are about difficulties loading photos in the chat, which rarely appear in other issues. 

This difference made sense from the theoretical point of view of stakeholders, because users with incorrect items are requested to provide photos as a proof of having received the incorrect items. 

We further check if this difference in the distribution of problems is statistically significant, using a chi-square test. Also, since some expected frequencies were below 5, Fisher’s exact test was also conducted as a robustness check. 

```{r}
# Perform the chi-square test 
chisq.test(table.problems)
#Perform the Fisher test
fisher.test(table.problems)

```

Both the chi-square test and Fisher’s exact test confirmed that the distribution of slow resolution problems significantly differed between incorrect item cases and other issues, supporting the idea that incorrect item complaints are uniquely shaped by the requirement of uploading photos.


### 5.3.2.1 Exploring the Correspondence of Additional Complaints and Specific Problems

In order to disentangle whether the larger number of slow resolution complaints in incorrect item cases is mainly driven by photo upload problems, we integrate the coding of complaint type with the presence/absence of slow resolution complaints. This allows us to visualize both the absolute and relative contribution of each type of problem across conditions. 

We first create a variable that integrates both the presence of complaints and the type of probelem complained about

```{r}
# Create a factor variable that indicates both the presence of complaints and the problems in the complaints
data.ch.i$sp.solve.problem.c <- as.character(data.ch.i$sp.solve.problem)
data.ch.i$sp.solve.problem.c [data.ch.i$complain.sp.solve == 0] <- "No slow resolution complain"
data.ch.i$sp.solve.problem.c <- factor (data.ch.i$sp.solve.problem.c, levels = c("No slow resolution complain", "Difficulties loading photos","Unespecific", "Slow information check"))


#Check if the recodification worked as expected
summary(data.ch.i)

```

Then we specify a function to obtain the percentages of each category of a dependent variable  across all the levels of our factor, and the binomial 95% confidence intervals

```{r}
f.prop.multicategory.1f <- function(my.data, my.dv, my.factor){
  
  # Initialize an empty list to store the sampled subsets from each stratum.
  results <- list() 
  
  # Initialize a counter for indexing elements in the 'results' list.
  p <- 1 
  
  # Obtain the levels of the dependent variable and the factor
  dv.levels <- unique (my.data[[my.dv]])
  f.levels <- unique (my.data[[my.factor]])
  
  #Create a loop for each factor level
    for (fl in f.levels){
      
    #Extract the vector and clean for missing cases
    current.vector <- my.data[my.data[[my.factor]]== fl, my.dv]
    current.vector.c <- current.vector[!is.na(current.vector)] #cleaning missing cases
      
      #Create a loop for each dv level  
      for (dvl in dv.levels){
          
      # Extract the successes and number of cases
      n <- length(current.vector.c) # number of cases in the vector
      s <- length(current.vector.c[current.vector.c == dvl]) # number of cases satisfying the condition
          
          # Calculate proportions and their 95% CI
          if(n > 0){
            proportion <- s / n #calculating proportions
            binomial.test <- binom.test (s, n) # binomial test to calculate 95% CI of the proportions
            ci_lower <- binomial.test$conf.int[1] #extracting the lower limit of the CI
            ci_upper <- binomial.test$conf.int[2] #extracting the upper limit of the CI    
          }else{
            proportion <- NA
            ci_lower <- NA
            ci_upper <- NA
          }

          # Save the results in a named vector
          results [[p]] <- data.frame(factor = fl, dv.level = dvl, percentage = proportion * 100, 
                           ci_lower.perc = ci_lower * 100, ci_upper.perc = ci_upper * 100, stringsAsFactors = FALSE)
          p <- p + 1 
          

      } # close the loop for the dv levels
    } # close the loop for the factor levels

  #Combine the results in a dataframe and convert outcomes to numeric columns
  results.df <- (do.call(rbind, results))
  rownames(results.df) <- NULL

  #Return the dataframe
  return(results.df)
}

```


Then we apply the function to our dependent variable - the presence and type of slow resolution complaints - and to our factor - chat attention to incorrect item cases or to other cases. 

```{r}
complaints.problems.df <- f.prop.multicategory.1f(data.ch.i, "sp.solve.problem.c", "condition")
complaints.problems.df

```


```{r}

# Specify the order for the presentation of the dv levels

complaints.problems.df$dv.level <- factor(complaints.problems.df$dv.level, levels = c("No slow resolution complain", "Difficulties loading photos","Unespecific", "Slow information check"))

# Gráfico con barras apiladas proporcionales usando tu dataframe
ggplot(complaints.problems.df, aes(x = factor, y = percentage, fill = dv.level)) +
  geom_col(position = "stack", width = 0.6) +

  # Etiquetas de ejes y título
  labs(x = "Condition",
       y = "% of Cases",
       fill = "Problem type",
       title = "Distribution of Problems in Slow Resolution Complaints") +
  
  # Renombrar condiciones
  scale_x_discrete(labels = c("chat_incorrect_item" = "Incorrect item",
                              "chat_other_issues" = "Other issue")) +
  
  # Colores manuales
  scale_fill_manual(values = c(
    "No slow resolution complain" = "grey95",      
    "Difficulties loading photos" = "antiquewhite4", 
    "Slow information check" = "antiquewhite1",      
    "Unespecific" = "antiquewhite3"                  
  )) +
  
  theme_minimal(base_size = 14)


```


```{r}
ggplot(complaints.problems.df, aes(x = factor, y = percentage, fill = dv.level)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
                position = position_dodge(width = 0.8),
                width = 0.2, color = "black") +
  labs(x = "Condition",
       y = "% of Cases",
       fill = "Complaint type",
       title = "Distribution of slow resolution complaint types across conditions") +
  scale_x_discrete(labels = c("chat_incorrect_item" = "Incorrect item",
                              "chat_other_issues" = "Other issue")) +
  scale_fill_manual(values = c(
    "No slow resolution complain" = "grey95",
    "Difficulties loading photos" = "antiquewhite4",
    "Slow information check" = "antiquewhite1",
    "Unespecific" = "antiquewhite3"
  )) +
  theme_minimal(base_size = 14)

```



SEGUIR ADAPTANDO EL CÓDIGO: 
- Guardar estas gráficas y procedimientos: para cuando hay variables multicategóricas, para ponerlo con y sin CI
- Reescribir: 
  - simular los datos para que las categorías no sean excluyentes. 
  - ver si hay diferencias con chi cuadrados entre las condiciones. utilizar una fórmula de agrupación, como by
  - aplicar fórmula de variables dicotómicas y su representación gráfica (reutilizar de antes). 
  - recodificar las variable a una sola de tal manera que pueda ver la contribución del problema de las photos, siguiendo el gráfico que hay he hecho aquí. 

- Modelar el impacto de las distintas quejas. 

  






```{r}

# Obtain the frequency table
table.problems.c <- with (complaints.problems.df, table(sp.solve.problem.c, condition))
table.problems.c

#Mark the order of the condition variable
data.ch.i$condition <- factor (data.ch.i$condition, levels = c("chat_incorrect_item", "chat_other_issue"))

#Graph the distribution across conditions
ggplot(data.ch.i, aes(x = condition, fill = sp.solve.problem.c)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Condition",
       y = "% of Cases",
       fill = "Complaint type",
       title = "Distribution of slow resolution complaint types across conditions") + 
  scale_x_discrete(labels = c ("Incorrect item", "Other issue")) +
  scale_fill_manual(values = c(
    "No slow resolution complain" = "grey95",  # gris muy claro
    "Difficulties loading photos" = "antiquewhite4", # verde
    "Slow information check" = "antiquewhite1",      # naranja
    "Unespecific" = "antiquewhite3"                  # violeta
  )) +
      theme_minimal()



```







```{r}

# Obtain the frequency table
table.problems.c <- with (data.ch.i, table(sp.solve.problem.c, condition))
table.problems.c

#Mark the order of the condition variable
data.ch.i$condition <- factor (data.ch.i$condition, levels = c("chat_incorrect_item", "chat_other_issue"))

#Graph the distribution across conditions
ggplot(data.ch.i, aes(x = condition, fill = sp.solve.problem.c)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Condition",
       y = "% of Cases",
       fill = "Complaint type",
       title = "Distribution of slow resolution complaint types across conditions") + 
  scale_x_discrete(labels = c ("Incorrect item", "Other issue")) +
  scale_fill_manual(values = c(
    "No slow resolution complain" = "grey95",  # gris muy claro
    "Difficulties loading photos" = "antiquewhite4", # verde
    "Slow information check" = "antiquewhite1",      # naranja
    "Unespecific" = "antiquewhite3"                  # violeta
  )) +
      theme_minimal()






```
```{r}
ggplot(data.ch.i, aes(x = condition, fill = sp.solve.problem.c)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Condition",
       y = "Proportion",
       fill = "Complaint type",
       title = "Distribution of slow resolution complaint types across conditions") + 
  scale_x_discrete(labels = c("chat_incorrect_item" = "Incorrect item", 
                              "chat_other_issues" = "Other issue")) +
  scale_fill_manual(values = c(
    "No slow resolution complain" = "grey90",  # gris muy claro
    "difficulties_loading_photos" = "#1b9e77", # verde
    "slow_information_check" = "#d95f02",      # naranja
    "unespecific" = "#7570b3"                  # violeta
  )) +
  theme_minimal()

```


```{r}

# Plotting the bar graph
ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  facet_wrap(~ dep.variable, 
             scales = "fixed", 
             axes = "all", 
             labeller = labeller(dep.variable = custom_titles)) +
  labs(
    y = "% of Complaints",
    fill = "Country",
    title = "% of Chat Complaints by Issue Type"
  ) +
  scale_x_discrete(labels = c ("incorrect item", "other issue")) +
  ylim(0, 100) +  
  geom_text(
    aes(label = paste0(round(percentage, 0), "%")),         # label with percentage rounded
    position = position_dodge(width = 0.8),   # match the dodge of bars
    vjust = -3,                             # slightly above the bar
    size = 2.5                                # text size
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.title.x = element_blank(),
    legend.position = c(1, 0),
    legend.justification = c("right", "bottom"),
    legend.title = element_text(size = 10, face = "bold"),
    legend.text  = element_text(size = 10),
    panel.spacing = unit(1, "lines"),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0.5),  
    plot.margin = margin(10, 5, 10, 5)
  )
```



SEGUIR AQUÍ:
- Graficar la frecuencia en ambas condiciones: un gráfico de barras con categorías distribuidas entre 0 y 100 en la misma barra. 
- Modelar la influencia de corregir el issue: 
  - Modelando el impacto de las quejas en la creación de detractores (¿puedo incluir quejas generales de sp.solve para ver si su efecto es significativo tras incluir las quejas específicas...?, no creo que sea posible, pues es una variable que está totalmente contenida en las quejas específicas. Parece no necesario)
  - Simular una base de datos con valores predichos al caso de que se eliminen los problemas
  







```{r}
library(ggplot2)
library(RColorBrewer)

ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    vjust = -0.5,
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom"
  )


```



```{r}
library(ggplot2)
library(RColorBrewer)

ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    vjust = -0.5,
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )


```

Make the graph



```{r, fig.width=8, fig.height=10}


ggplot(prop.df, aes(x = factor1, y = percentage, fill = factor2)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_lower.perc, ymax = ci_upper.perc),
    position = position_dodge(width = 0.8),
    width = 0.2
  ) +
  geom_text(
    aes(label = sprintf("%.1f%%", percentage)),
    position = position_dodge(width = 0.8),
    hjust = -0.7,  # en horizontal cambiamos de vjust -> hjust
    size = 3
  ) +
  facet_wrap(~ dep.variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Método",
    y = "Porcentaje (%)",
    fill = "Razón de queja",
    title = "Porcentajes e IC 95% por variable dependiente, método y razón"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "bottom"
  ) +
  coord_flip()


```


```{r}

```

