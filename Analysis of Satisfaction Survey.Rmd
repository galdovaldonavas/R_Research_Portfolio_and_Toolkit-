---
title: "Analysis of Satisfaction Survey"
output: html_notebook
---


# 0. Setup

```{r}
library(psych)
library(ggplot2)
```


# 1. Data Simulation

## 1.1. Simulation of demographic and contextual variables
Variables <- c("gender", "age", "method", "country", "reason", "nps_score", "satisfaction", "complain.connect", "complain.respond.vel", "complain.solve.vel", "complain.repeat" )

```{r}

set.seed(1000)

data.n <- 5*4*2*1000

data <- data.frame (id = as.factor(c(1:data.n)))


data$age <- round(rlnorm(n=data.n, meanlog= log(40), sdlog=log(1.4)))
data$age [data$age>90] <- 90
data$age [data$age<15] <- 15

data$gender <- factor(sample(c("man", "woman"), prob= c(0.5, 0.5), replace= TRUE, size = data.n))
data$country <- factor(sample(c("Drinkland","Eatland"), prob= c(0.5, 0.5), replace= TRUE, size = data.n))
data$method <- factor(sample(c("chat", "web_form", "email", "phone"), prob= c(0.4, 0.10,0.15, 0.35), replace= TRUE, size = data.n))
data$reason <- factor(sample(c("incorrect_item", "delay", "status","cancellation", "other"), prob= c(0.2, 0.3,0.2,0.1, 0.2), replace= TRUE, size = data.n))
data$open.comment <- rep("bla bla", data.n)


```

## Simulation of frequency of complaints depending of the demographic and contextual factors

We will simulate the presence of complaints about the connection (complain.connect), the speed to respond (complain.sp.respond), the speed to solve the problem (complain.sp.solve) and complains about repeating information (complain.repeat), attending to several factors: 

- complaints about connection will be higher in the country Drinkland
- complaints about speed to response will strongly higher in email, and moderately higher in chat and web forms. 
- complaints about speed to solve will be higher in incorrect item deliveries attended through chat.
- complaints about the need to repeat information will be higher in order cancellation. 
- other complaints have similar distribution across countries, contact reasons and contact methods

For each type of complaint we will set an initial probability, then we will alter that probability depending on the presence of the mentioned factors. 

```{r}

##For connection complaints
# we set an initial probability of 0.1 of the complaints to appear
con.prob <- rep(0.1,data.n) 
# we set a double probability of connection complains in Drinkland
con.prob [data$country=="Drinkland"] <- con.prob [data$country=="Drinkland"] *2 
#We ensure the probabilities are contained between 0 and 1 (for prevention in further transformations)
con.prob[con.prob>1] <- 1
con.prob[con.prob<0] <- 0
#we create the variable attending the above probabilities for each of our cases
data$complain.connect<- rbinom(n=data.n, size =1, prob=con.prob)
#to check the results are as expected: 
with(data,prop.table(table(complain.connect,country), margin=2))


##For complaints about the speed to respond
# we set an initial probability of 0.05 of the complaints to appear
spr.prob <- rep(0.05,data.n) 
# we set a 6 times higher probability for complains to appear for email
spr.prob [data$method=="email"] <- spr.prob [data$method=="email"] *6 
#We set a 3 times higher probability for complaints to appear for chat and web forms
spr.prob [data$method %in% c("chat", "web_form")] <- spr.prob [data$method %in% c("chat", "web_form")] *3
#We ensure the probabilities are contained between 0 and 1 (for prevention in further transformations)
spr.prob[spr.prob>1] <- 1
spr.prob[spr.prob<0] <- 0
#we create the variable attending the above probabilities for each of our cases
data$complain.sp.respond<- rbinom(n=data.n, size =1, prob=spr.prob)
#to check the results are as expected: 
with(data,prop.table(table(complain.sp.respond,method),margin=2))


##For complaints about the speed to solve
# we set an initial probability of 0.1 of the complaints to appear
sps.prob <- rep(0.1,data.n) 
# we set a 5 times higher probability for contact reasons of incorrect items that are attended by chat
sps.prob [data$method=="chat" & data$reason=="incorrect_item"] <- sps.prob [data$method=="chat" & data$reason=="incorrect_item"] *5
#We ensure the probabilities are contained between 0 and 1 (for prevention in further transformations)
sps.prob[sps.prob>1] <- 1
sps.prob[sps.prob<0] <- 0
#we create the variable attending the above probabilities for each of our cases
data$complain.sp.solve<- rbinom(n=data.n, size =1, prob=sps.prob)
#to check the results are as expected: 
with(data,prop.table(table(complain.sp.solve,reason,method),margin=c(2:3)))

##For complaints about the need to repeat information
# we set an initial probability of 0.02 of the complaints to appear
rp.prob <- rep(0.02,data.n) 
# we set a 10 times higher probability for contact reasons about cancellations
rp.prob [data$reason=="cancellation"] <- rp.prob [data$reason=="cancellation"] *10
#We ensure the probabilities are contained between 0 and 1 (for prevention in further transformations)
rp.prob[rp.prob>1] <- 1
rp.prob[rp.prob<0] <- 0
#we create the variable attending the above probabilities for each of our cases
data$complain.repeat<- rbinom(n=data.n, size =1, prob=rp.prob)
#to check the results are as expected: 
with(data,prop.table(table(complain.repeat,reason),margin=2))

##For other complaints

data$complain.other<- rbinom(n=data.n, size =1, prob=.2)
#to check the results are as expected: 
with(data,prop.table(table(complain.other)))

```





##Simulation of NPS scores 

We first assume a normal distribution of responses in the ideal case in which customers have no complaints.  
Then we apply the corrections based on the information we have simulated about the presence of different complaints. 

At the end, we limit the scores to 0 and 10 and transform them to integers, in line with restrictions of NPS scores. 

```{r}

#Preliminary distribution in case of no complaints. We use a high mean value
data$nps.score <- rnorm(data.n, mean=9, sd= 2)


#We adjust the scores for the presence of complaints. We are applying fixed penalties to NPS scores based on the presence of complaints (e.g., 3 points if there are connection complaints).While using a binomial distribution could add randomness (and realism), we opt for fixed values to make the relationships easier to interpret. 
data$nps.score <- data$nps.score -
3 * data$complain.connect -
4 * data$complain.sp.respond -
6 * data$complain.sp.solve -
2 * data$complain.repeat -
1 * data$complain.other 

# to limit the values between 0 and 10:
data$nps.score[data$nps.score<0] <- 0
data$nps.score[data$nps.score>10] <- 10 

# to convert to integer values
data$nps.score <- floor (data$nps.score)


#to see the distribution of scores

barplot(table(data$nps.score)) 

with(data,(prop.table(table(data$nps.score))))


```


### Specifying the NPS segments based on NPS scores

```{r}
data$nps.segment <- rep(NA_character_, data.n)

data$nps.segment [data$nps.score<=6] <- "detractor"
data$nps.segment [data$nps.score >6 & data$nps.score <9] <- "passive"
data$nps.segment [data$nps.score>=9] <- "promoter"

data$nps.segment <- factor (data$nps.segment)

#to check the results
with(data, prop.table(table(nps.segment)))
```

##Simulation of satisfaction scores


```{r}

data$satisfaction <- floor(rnorm(data.n, mean = 3, sd=0.5) + 0.9 * (1 + as.numeric(scale(data$nps.score))))

data$satisfaction[data$satisfaction<1] <- 1
data$satisfaction[data$satisfaction>5] <- 5

# To see the distribution
barplot(table(data$satisfaction))
with(data,prop.table(table(satisfaction)))


# To check the correlation with NPS
with(data, cor(nps.score,satisfaction, method="spearman"))


```

##Simulation of missing data

###Missing data for satisfaction

We simulate that satisfaction was not available for the country Drinkland, and for the contact methods of email and webform. 
Additionally, within those situations in which the satisfaction item was available, there is 10% probability that customers do not answer to it.

```{r}

data$satisfaction[data$country=="Drinkland"]<- NA_real_
data$satisfaction[data$method %in% c("email","web_form")]<- NA_real_


na_randomizer <- sample(c(0,1), size=sum(!is.na(data$satisfaction)), replace=TRUE, prob= c(0.1,0.9))
data$satisfaction[which(!is.na(data$satisfaction))[ na_randomizer==0]]<- NA_real_

#We see the results
summary(data$satisfaction)

```





# 2. Exploration of Satisfaction and Probability to Recommend  across Methods, Reasons, and Countries

## 2.1. Measurement considerations
Our main goal was to understand customer satisfaction. But, we didn't have satisfaction data readily available for all countries and contact methods. Given this limitation, and because our key stakeholders were already familiar with it, we decided to use the Net Promoter Score (NPS) as our primary indicator.

NPS measures customer loyalty and how likely they are to recommend our services. It gave us a consistent way to evaluate customer perception across all the different areas we were interested in. For this analysis, NPS acted as a good proxy for overall customer experience and satisfaction.

To make sure NPS was a reliable stand-in for satisfaction, I took a few key steps:

- I checked for a strong correlation between satisfaction scores and NPS scores. I looked at whether the satisfaction score was correlated with both, the raw scores (the 0-10 scale used for NPS) and the categorical scores (the percentage of Promoters minus Detractors for NPS).

- For cases where we did have satisfaction data, I ran parallel analyses using those scores. This helped me see if the trends and insights matched what we found with NPS, or if any new patterns emerged.

## 2.1.1. Correlations between satisfaction scores and NPS scores

We first explored the distribution shapes for both satisfaction and nps scores, using bar charts from the ggplot2 package: 

```{r}
# Distribution of the NPS scores: 

ggplot(data[!is.na(data$nps.score), ], aes(x = factor(nps.score))) +
  geom_bar(fill = "#2980b9") +
  labs(
    title = "Distribution of NPS Scores",
    x = "NPS Score",
    y = "Count"
  ) +
  theme_minimal()

# Distribution of satisfaction scores: 

ggplot(data[!is.na(data$satisfaction), ], aes(x = factor(satisfaction))) +
  geom_bar(fill = "#27ae60") +
  labs(
    title = "Distribution of Satisfaction",
    x = "Satisfaction Score",
    y = "Count"
  ) +
  theme_minimal()
```
Neither of the distributions follows a normal distribution, with both nps.score and satisfaction showing left-skewed patterns. Notably, the distribution of nps.score also shows signs of a ceiling effect, with a considerable proportion of scores concentrated at the upper end of the scale.

Given these distributional characteristics, Pearson's correlation is not an appropriate choice, as it assumes linearity and approximate normality, and can be highly sensitive to skewed or bounded data.

Before selecting a more robust correlation measure—such as Spearman's rank or polychoric correlation—we will inspect the relationship between nps.score and satisfaction using a scatterplot. This will allow us to visually assess the form and strength of the association and decide whether the relationship appears monotonic or not.

```{r}
# create the scatterplot (using the package ggplot 2)
ggplot(na.omit(data[, c("nps.score", "satisfaction")]), aes(x = jitter(nps.score), y = jitter(satisfaction))) +
  geom_point(alpha = 0.5, color = "#2c3e50") +
  labs(
    title = "Relation between NPS Scores and Satisfaction",
    x = "NPS Score",
    y = "Satisfaction"
  ) +
  theme_minimal()


```

The scatterplot reveals a strong monotonic and linear relationship between NPS score and Satisfaction. Considering that both variables are ordinal, we will use Spearman’s rank correlation, which assesses the strength of monotonic associations without requiring interval-level measurement or normal distribution.




```{r}
# The Spearman correlation (using the psych package): 
with(data, corr.test(nps.score, satisfaction, method="spearman", use= "complete.obs"))


```

Our analysis revealed a strong positive Spearman correlation between satisfaction and NPS scores, which provides confidence that NPS effectively serves as a proxy for customer satisfaction in this dataset. 



##2.2. Heatmaps of Scores Across Methods, Reasons, and Countries

### 2.2.1. Heatmap for satisfaction scores

For satisfaction we only had scores for one country (Eatland) and for 2 contact methods (phone and chat). However, these scores are expected to be a more valid measures of satisfaction than the NPS scores, so we will use them to see if they show a different pattern than the NPS scores.  

MY VERSIÓN
```{r}
# I create the practice database: 

my.data <- data.frame(matrix(NA, nrow= 10, ncol=5))
names(my.data) <- c("id", "my.dv", "factor.columns", "factor.rows", "factor.blocks")
my.data[, "id"] <- c(1,2,3,4,5,6,7,8,9,10)
my.data[, "my.dv"] <- c(5,5,5,5,5,3,3,3,3,3)
my.data[, "factor.columns"] <- c(rep("chat",5),rep("phone",5))
my.data[, "factor.rows"] <- rep(c(rep("status",2),rep("cancel",3)),2)
my.data[, "factor.blocks"] <- rep(c("Spain","Portugal"),5)

#I specify my function
my.function <-mean

# I create the list object to keep the results, and an object to index them (starting with 1)
results <- list()
k <- 1


#I obtain the unique levels of the factors
factor.column.levels <- unique(my.data[["factor.columns"]])
factor.rows.levels <- unique(my.data[["factor.rows"]])
factor.blocks.levels <- unique(my.data[["factor.blocks"]])

factor.column.levels
factor.rows.levels 
factor.blocks.levels 



# 1. Results for a general block that does not desagregate results by the block factor
    
#1.1. First line with totals
#it will contain the value for the whole sample, and this total desagregated by the column factor

##1.1.1 Create the label for specifying we refer to results of the whole sample
row.label.t <- paste0("Total all sample")

##1.1.2. Calculate the total results for the whole sample
if(nrow(my.data)>0){
  total <- my.function(my.data[["my.dv"]], na.rm=TRUE)
} else {stop("The dataset is empty")
}

##1.1.3. Calculate the total results for the columns factor
c.total <- sapply(factor.column.levels, function(c){
  c.subset <- my.data[ my.data[["factor.columns"]] == c, ]
  my.function(c.subset[["my.dv"]], na.rm= TRUE)
})

## 1.1.4. Save the results of this line in a named vector
results[[k]] <- c(group = row.label.t, overall = total, setNames(object= c.total, factor.column.levels) ) 
k <- k+1

# 1.2. Create additional lines for the general block
      #each line will shows results of the whole sample for each level of the row factor
      #and additional columns for that result desagregated by the colums factor 

##1.2.1. Create a loop for each level in the row factor
for (r in factor.rows.levels){
  
  ##1.2.2. Create a label for each line
  row.label.r <- paste0(r)
  
  ##1.2.3. Calculate the total for each level of the row factor
  r.total.subset <- my.data[my.data[["factor.rows"]]==r, ]
  r.total <- my.function(r.total.subset[["my.dv"]], na.rm=TRUE)
  
  ##1.2.4. Calculate the value for each level in the row factor
  rc.crossed <- sapply(factor.column.levels, function(c){
    rc.crossed.subset <- my.data[my.data[["factor.rows"]] == r &
                                   my.data[["factor.columns"]] == c
    , ]
    my.function(rc.crossed.subset[["my.dv"]], na.rm=TRUE)
  })

  ##1.2.5. We save the results
  results[[k]] <- c(group = row.label.r, overall = r.total, setNames(object=rc.crossed, factor.column.levels))
  k<- k+1
  
} # Close the loop for the levels of the row factor



# 2.Results for each level of the block factor

#2.1. first line with totals
# it will contain the results for the total of the block and that result desagregated by the column factor

# 2.1.1. We create a loop for each block
for (b in factor.blocks.levels){
  
  ## 2.1.2.Label the line to put the result for the block 
  row.label.b <- paste0("Total: ", b)
  
  ## 2.1.3.Calculate the total for the block
  b.subset <- my.data[ my.data[["factor.blocks"]]== b, ]
  b.total <- my.function(b.subset[["my.dv"]], na.rm=TRUE) 
  
  ## 2.1.4.Calculate the results for the block desagregated by the columns factor
  bc.crossed <- sapply(factor.column.levels, function(c){
    bc.crossed.subset <- my.data [ my.data[["factor.blocks"]] == b &
                                     my.data[["factor.columns"]] == c, ]
    if(length(bc.crossed.subset)>0) {my.function(bc.crossed.subset[["my.dv"]], na.rm=TRUE)
      }else{NA_real_}
  }) 
  
  ## 2.1.5. Save the results for the block in a named vector
  results [[k]] <- c(group = row.label.b, overall= b.total, setNames(object=bc.crossed, factor.column.levels))
  k<- k+1 
 
  
      # 2.2. Add the remaining lines corresponding to each block.
      #each line will shows the total results for each level of the row factor within that block, 
      #and that result desagregated by the column factor.     
  
      ## 2.2.1. Create a sub-loop for rows, within the prior loop of blocks 
      for(r in factor.rows.levels){ 
    
        ## 2.2.Label each line specifying the block and row crossed 
        row.label.br <- paste0(b, ": ", r)  
        
        ## 2.3.Obtain the result for the block and row factors crossed 
        br.crossed.subset <- my.data[my.data[["factor.blocks"]] == b &
                                      my.data[["factor.rows"]] == r
        , ]
        br.crossed <- my.function (br.crossed.subset[["my.dv"]], na.rm=TRUE)
  
        ## 2.4. Obtain the result for the cross of the three factors
        all.crossed <- sapply(factor.column.levels, function(c){
        all.crossed.subset <- my.data[my.data[["factor.blocks"]] == b & 
                                    my.data[["factor.rows"]]==r &
                                    my.data[["factor.columns"]] == c, ]
          if (nrow(all.crossed.subset) > 0){my.function(all.crossed.subset[["my.dv"]], na.rm =TRUE)}
            else {NA_real_} #
        })
    
        ## 2.5. Save the results of each line in a named vector
        results [[k]] <- c(group= row.label.br, overall = br.crossed, setNames(object=all.crossed, factor.column.levels))
        k <- k+1
        
      } ###close the loop for the rows factor
 
} ### close the loop for the blocks factor


  
# 3. We agregate the results in a dataframe  
results.df <- do.call(rbind, results)



```


I PASS IT TO A FUNCTION



```{r}

f.heatmap.3f <- function(my.data, my.dv, factor.columns, factor.rows, factor.blocks, my.function){


# Create the list object to keep the results, and an object to index them (starting with 1)
results <- list()
k <- 1


#I obtain the unique levels of the factors
factor.column.levels <- unique(my.data[[factor.columns]])
factor.rows.levels <- unique(my.data[[factor.rows]])
factor.blocks.levels <- unique(my.data[[factor.blocks]])


# 1. Results for a general block that does not desagregate results by the block factor
    
#1.1. First line with totals
#it will contain the value for the whole sample, and this total desagregated by the column factor

##1.1.1 Create the label for specifying we refer to results of the whole sample
row.label.t <- paste0("Total all sample")

##1.1.2. Calculate the total results for the whole sample
if(nrow(my.data)>0){
  total <- my.function(my.data[[my.dv]], na.rm=TRUE)
} else {stop("The dataset is empty")
}

##1.1.3. Calculate the total results for the columns factor
c.total <- sapply(factor.column.levels, function(c){
  c.subset <- my.data[ my.data[[factor.columns]] == c, ]
  my.function(c.subset[[my.dv]], na.rm= TRUE)
})

## 1.1.4. Save the results of this line in a named vector
results[[k]] <- c(group = row.label.t, overall = total, setNames(object= c.total, factor.column.levels) ) 
k <- k+1

# 1.2. Create additional lines for the general block
      #each line will shows results of the whole sample for each level of the row factor
      #and additional columns for that result desagregated by the colums factor 

##1.2.1. Create a loop for each level in the row factor
for (r in factor.rows.levels){
  
  ##1.2.2. Create a label for each line
  row.label.r <- paste0(r)
  
  ##1.2.3. Calculate the total for each level of the row factor
  r.total.subset <- my.data[my.data[[factor.rows]]==r, ]
  r.total <- my.function(r.total.subset[[my.dv]], na.rm=TRUE)
  
  ##1.2.4. Calculate the value for each level in the row factor
  rc.crossed <- sapply(factor.column.levels, function(c){
    rc.crossed.subset <- my.data[my.data[[factor.rows]] == r &
                                   my.data[[factor.columns]] == c
    , ]
    my.function(rc.crossed.subset[[my.dv]], na.rm=TRUE)
  })

  ##1.2.5. We save the results
  results[[k]] <- c(group = row.label.r, overall = r.total, setNames(object=rc.crossed, factor.column.levels))
  k<- k+1
  
} # Close the loop for the levels of the row factor



# 2.Results for each level of the block factor

#2.1. first line with totals
# it will contain the results for the total of the block and that result desagregated by the column factor

# 2.1.1. We create a loop for each block
for (b in factor.blocks.levels){
  
  ## 2.1.2.Label the line to put the result for the block 
  row.label.b <- paste0("Total: ", b)
  
  ## 2.1.3.Calculate the total for the block
  b.subset <- my.data[ my.data[[factor.blocks]]== b, ]
  b.total <- my.function(b.subset[[my.dv]], na.rm=TRUE) 
  
  ## 2.1.4.Calculate the results for the block desagregated by the columns factor
  bc.crossed <- sapply(factor.column.levels, function(c){
    bc.crossed.subset <- my.data [ my.data[[factor.blocks]] == b &
                                     my.data[[factor.columns]] == c, ]
    if(nrow(bc.crossed.subset)>0) {my.function(bc.crossed.subset[[my.dv]], na.rm=TRUE)
      }else{NA_real_}
  }) 
  
  ## 2.1.5. Save the results for the block in a named vector
  results [[k]] <- c(group = row.label.b, overall= b.total, setNames(object=bc.crossed, factor.column.levels))
  k<- k+1 
 
  
      # 2.2. Add the remaining lines corresponding to each block.
      #each line will shows the total results for each level of the row factor within that block, 
      #and that result desagregated by the column factor.     
  
      ## 2.2.1. Create a sub-loop for rows, within the prior loop of blocks 
      for(r in factor.rows.levels){ 
    
        ## 2.2.Label each line specifying the block and row crossed 
        row.label.br <- paste0(b, ": ", r)  
        
        ## 2.3.Obtain the result for the block and row factors crossed 
        br.crossed.subset <- my.data[my.data[[factor.blocks]] == b &
                                      my.data[[factor.rows]] == r
        , ]
        br.crossed <- my.function (br.crossed.subset[[my.dv]], na.rm=TRUE)
  
        ## 2.4. Obtain the result for the cross of the three factors
        all.crossed <- sapply(factor.column.levels, function(c){
        all.crossed.subset <- my.data[my.data[[factor.blocks]] == b & 
                                    my.data[[factor.rows]]==r &
                                    my.data[[factor.columns]] == c, ]
          if (nrow(all.crossed.subset) > 0){my.function(all.crossed.subset[[my.dv]], na.rm =TRUE)}
            else {NA_real_} #
        })
    
        ## 2.5. Save the results of each line in a named vector
        results [[k]] <- c(group= row.label.br, overall = br.crossed, setNames(object=all.crossed, factor.column.levels))
        k <- k+1
        
      } ###close the loop for the rows factor
 
} ### close the loop for the blocks factor


  
# 3. We agregate the results in a dataframe and return the dataframe

results.df <- as.data.frame(do.call(rbind, results), stringsAsFactors = FALSE)

return(results.df)
}



```






```{r}

heatmap_df2 <- f.heatmap.3f (
  my.data = data,
  my.dv = "satisfaction",
  factor.columns = "method",
  factor.rows = "reason",
  factor.blocks = "country",
  my.function = mean
)

```


OTHER CLEAN VERSION

```{r}

f.heatmap.3f <- function(my.data, my.dv, factor.columns, factor.rows, factor.blocks, my.function) {
  
  # 0. Comprobación de dataset vacío
  if (nrow(my.data) == 0) stop("The dataset is empty")
  
  # 1. Inicialización
  results <- list()
  k <- 1
  
  # 2. Obtención de niveles únicos de cada factor
  factor.column.levels <- unique(my.data[[factor.columns]])
  factor.rows.levels   <- unique(my.data[[factor.rows]])
  factor.blocks.levels <- unique(my.data[[factor.blocks]])
  
  # --------------------
  # 3. BLOQUE GENERAL (sin desagregar por bloques)
  # --------------------
  
  # 3.1 Línea de totales para toda la muestra
  row.label.t <- "Total all sample"
  total <- my.function(my.data[[my.dv]], na.rm = TRUE)
  
  c.total <- sapply(factor.column.levels, function(c) {
    c.subset <- my.data[my.data[[factor.columns]] == c, ]
    my.function(c.subset[[my.dv]], na.rm = TRUE)
  })
  
  results[[k]] <- c(group = row.label.t, overall = total,
                    setNames(c.total, factor.column.levels))
  k <- k + 1
  
  # 3.2 Líneas por cada nivel de factor.rows
  for (r in factor.rows.levels) {
    row.label.r <- r
    r.total.subset <- my.data[my.data[[factor.rows]] == r, ]
    r.total <- my.function(r.total.subset[[my.dv]], na.rm = TRUE)
    
    rc.crossed <- sapply(factor.column.levels, function(c) {
      rc.subset <- my.data[my.data[[factor.rows]] == r &
                             my.data[[factor.columns]] == c, ]
      my.function(rc.subset[[my.dv]], na.rm = TRUE)
    })
    
    results[[k]] <- c(group = row.label.r, overall = r.total,
                      setNames(rc.crossed, factor.column.levels))
    k <- k + 1
  }
  
  # --------------------
  # 4. BLOQUE POR CADA NIVEL DE factor.blocks
  # --------------------
  for (b in factor.blocks.levels) {
    row.label.b <- paste0("Total: ", b)
    b.subset <- my.data[my.data[[factor.blocks]] == b, ]
    b.total <- my.function(b.subset[[my.dv]], na.rm = TRUE)
    
    bc.crossed <- sapply(factor.column.levels, function(c) {
      bc.subset <- b.subset[b.subset[[factor.columns]] == c, ]
      if (nrow(bc.subset) > 0) my.function(bc.subset[[my.dv]], na.rm = TRUE)
      else NA_real_
    })
    
    results[[k]] <- c(group = row.label.b, overall = b.total,
                      setNames(bc.crossed, factor.column.levels))
    k <- k + 1
    
    # 4.2 Líneas por cada nivel de factor.rows dentro de cada bloque
    for (r in factor.rows.levels) {
      row.label.br <- paste0(b, ": ", r)
      br.subset <- b.subset[b.subset[[factor.rows]] == r, ]
      br.total <- my.function(br.subset[[my.dv]], na.rm = TRUE)
      
      all.crossed <- sapply(factor.column.levels, function(c) {
        all.subset <- br.subset[br.subset[[factor.columns]] == c, ]
        if (nrow(all.subset) > 0) my.function(all.subset[[my.dv]], na.rm = TRUE)
        else NA_real_
      })
      
      results[[k]] <- c(group = row.label.br, overall = br.total,
                        setNames(all.crossed, factor.column.levels))
      k <- k + 1
    }
  }
  
  # --------------------
  # 5. Convertimos a data.frame y devolvemos
  # --------------------
  results.df <- as.data.frame(do.call(rbind, results), stringsAsFactors = FALSE)
  colnames(results.df) <- make.names(colnames(results.df))
  
  return(results.df)
}



```




```{r}

sat.means <- aggregate(satisfaction ~ method + reason + country, data = data, mean)


f.heatmap.3f <- function(my.data, my.dv, factor.columns, factor.rows, factor.blocks, my.function){
  
  factor.blocks.levels <- unique(my.data[[factor.blocks]])
  factor.rows.levels <- unique(my.data[[factor.rows]])
  factor.columns.levels <- unique(my.data[[factor.columns]])
  
  results.df <- data.frame(column= c(block.name, block.result, row.names, row.result, factor.column.levels)
                            row.names = rep(c=(block.result,factor.rows.levels, column.result), length(factor.blocks.levels))
  )
  
  for (i in unique(my.data[[factor.blocks]])){
    block.subset <- my.data[my.data[[factor.blocks]]=="i"]
    block.subset.clean <- block.subset[!is.na(block.subset[[my.dv]])]
    
    if(length(block.subset.clean)==0){
      warning(paste0("no data for calculating a block function"))
    }
  }
}

```



Versión previa por listas

```{r}

f.heatmap.3f.clean <- function(my.data, my.dv,
                               factor.columns, factor.rows, factor.blocks,
                               my.function = mean, na.rm = TRUE) {
  
  col.levels <- unique(my.data[[factor.columns]])
  row.levels <- unique(my.data[[factor.rows]])
  block.levels <- unique(my.data[[factor.blocks]])
  
  results <- list()
  k <- 1
  
  # 1. Cruce de row x block
  for (b in block.levels) {
    for (r in row.levels) {
      row.values <- sapply(col.levels, function(clvl) {
        temp <- subset(my.data,
                       my.data[[factor.blocks]] == b &
                       my.data[[factor.rows]] == r &
                       my.data[[factor.columns]] == clvl)
        if (nrow(temp) > 0) my.function(temp[[my.dv]], na.rm = na.rm) else NA_real_
      })
      overall <- my.function(subset(my.data,
                                    my.data[[factor.blocks]] == b &
                                    my.data[[factor.rows]] == r)[[my.dv]], na.rm = na.rm)
      
      row.label <- paste0("Block: ", b, " | Row: ", r)
      results[[k]] <- c(group = row.label, result = overall, setNames(row.values, col.levels))
      k <- k + 1
    }
  }
  
  # 2. Agregados por bloque
  for (b in block.levels) {
    row.values <- sapply(col.levels, function(clvl) {
      temp <- subset(my.data,
                     my.data[[factor.blocks]] == b &
                     my.data[[factor.columns]] == clvl)
      if (nrow(temp) > 0) my.function(temp[[my.dv]], na.rm = na.rm) else NA_real_
    })
    overall <- my.function(subset(my.data, my.data[[factor.blocks]] == b)[[my.dv]], na.rm = na.rm)
    row.label <- paste0("Total (Block: ", b, ")")
    results[[k]] <- c(group = row.label, result = overall, setNames(row.values, col.levels))
    k <- k + 1
  }
  
  # 3. Agregados por fila
  for (r in row.levels) {
    row.values <- sapply(col.levels, function(clvl) {
      temp <- subset(my.data,
                     my.data[[factor.rows]] == r &
                     my.data[[factor.columns]] == clvl)
      if (nrow(temp) > 0) my.function(temp[[my.dv]], na.rm = na.rm) else NA_real_
    })
    overall <- my.function(subset(my.data, my.data[[factor.rows]] == r)[[my.dv]], na.rm = na.rm)
    row.label <- paste0("Total (Row: ", r, ")")
    results[[k]] <- c(group = row.label, result = overall, setNames(row.values, col.levels))
    k <- k + 1
  }
  
  # Combinar en un dataframe
  df <- as.data.frame(do.call(rbind, results), stringsAsFactors = FALSE)
  colnames(df)[1:2] <- c("group", "result")
  df[, -1] <- lapply(df[, -1], as.numeric)
  
  return(df)
}


heatmap_df <- f.heatmap.3f.clean (
  my.data = data,
  my.dv = "satisfaction",
  factor.columns = "method",
  factor.rows = "reason",
  factor.blocks = "country",
  my.function = mean
)

```





```


































































### Selection of the sample for the analyses of complaints

Although we initially simulated complaints for all subjects in the dataset, we didn't have this data available for all our cases. This data came from further coding for subgroups we wanted to do follow-up analyses (see Section X). Based on this, we're now selecting a stratified sample of 100 cases for each of the available contact methods, for each of the four contact reasons of interest ("incorrect_item", "delay", "status", "cancellation"), and for each of the two relevant countries. This ensures a balanced representation across key dimensions for our specialized analyses.

Specifically, for each method, reason, and country combination, we aim to obtain a sample of 100 subjects and store the results in a new dataset.

```{r}
# Optional: Examine the distribution of our current data across the key factors.
with(data, table(method, reason, country))



#  --- Define a Function to perform stratified sampling ---
# This function takes the desired number of samples per group (my.n),
# the original dataset (my.data), and the names of the three factor columns
# (my.factor1, my.factor2, my.factor3) as character strings.

f.sample.3f <- function(my.n, my.data, my.factor1, my.factor2, my.factor3){
  
  # Input validation: Ensure factor names are passed as character strings.
  if (!is.character(my.factor1) || !is.character(my.factor2) || !is.character(my.factor3)) {
    stop("The factors have to be character chains, with names within quotation marks.")
  }
  
  # Initialize an empty list to store the sampled subsets from each stratum.
  results <- list() 
  
  # Initialize a counter for indexing elements in the 'results' list.
  k <- 1 
  
  # Iterate through each unique level of the first factor.
  for (i in unique(my.data[[my.factor1]])){
    # Within each level of the first factor, iterate through unique levels of the second factor.
    for(j in unique(my.data[[my.factor2]])){
      # Within each combination of the first two factors, iterate through unique levels of the third factor.
      for (q in unique (my.data[[my.factor3]])){
        
        # Filter the original dataframe to get the subset of data
        current.subset <- my.data[my.data[[my.factor1]] == i & 
                                  my.data[[my.factor2]] == j & 
                                  my.data[[my.factor3]] == q, ]
          
        # Get the number of rows (cases) in the current subset.
        current_rows <- nrow(current.subset)
          
        # Sampling logic based on the size of the current group:
        if(current_rows == 0){
          # If the group has no cases, issue an informative warning and go to the next loop
          warning(paste0("The group (", my.factor1, "=", i, ", ", my.factor2, "=", j, ", ", 
                         my.factor3, "=", q, ") has no cases."))
          next 
        } else if (current_rows >= my.n){
          # If the group has  equal to or greater cases than the desired n, we take a random sample:
          current.subset <- current.subset[sample(current_rows, my.n), ]
        } else if (current_rows < my.n) {
          # If the group has fewer cases than desired n, include all available cases, with a warning.
          warning(paste0("The group (", my.factor1, "=", i, ", ", my.factor2, "=", j, ", ", 
                         my.factor3, "=", q, ") has less cases than the expected n. All available cases will be included."))
        }
          
        # Add the processed subset (either sampled or full) to our list of results.
        results[[k]] <- current.subset
        # Increment the counter for the next element in the list.
        k <- k+1
          
      } # End of the third factor (q) loop
    } # End of the second factor (j) loop
  } # End of the first factor (i) loop

  # Final check: If the 'results' list is empty after all loops,
  # it means no groups could be sampled (e.g., all were empty).
  # In this case, return an empty dataframe.
  if (length(results) == 0) {
    message("No groups met the sampling criteria or all groups were empty. Returning an empty data frame.")
    return(data.frame())
  }
  
  # Combine all dataframes from the 'results' list into a single dataframe.
  # do.call(rbind, ...) is an efficient way to achieve this.
  sample.df <- do.call(rbind, results)
  
  # Return the final sampled dataframe.
  return(sample.df)
}


# --- Execute the Sampling Function ---

data.complaints <- f.sample.3f(
  my.n = 100,             # Desired number of cases per stratum
  my.data = data,         # Your input dataframe
  my.factor1 = "method",  # Column name for the first factor (as a character string)
  my.factor2 = "reason",  # Column name for the second factor (as a character string)
  my.factor3 = "country"  # Column name for the third factor (as a character string)
)


# Optional: examine the distribution of our sample across the key factors.
with(data.complaints, table(method, reason, country))
summary(data.complaints)

```


correlación y scatterplot
código para la matriz de NPS
con algún análisis acompañando: ver si uso modelo lineal o logarítmico






